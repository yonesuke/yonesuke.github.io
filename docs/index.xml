<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ryosuke Yoneda&#39;s Homepage</title>
    <link>https://yonesuke.github.io/</link>
    <description>Recent content on Ryosuke Yoneda&#39;s Homepage</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Ryosuke Yoneda</copyright>
    <lastBuildDate>Sun, 18 Apr 2021 21:20:05 +0900</lastBuildDate><atom:link href="https://yonesuke.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>包除原理</title>
      <link>https://yonesuke.github.io/posts/inclusion_exclusion/</link>
      <pubDate>Sun, 16 May 2021 12:18:18 +0900</pubDate>
      
      <guid>https://yonesuke.github.io/posts/inclusion_exclusion/</guid>
      <description>測度空間$(X,\mathcal{B},\mu)$の有限測度集合$A_{i}(i=1,\dots,n)$に対して $$ \mu\left(\bigcup_{i=1}^{n}A_{i}\right)=\sum_{J\subset[n];J\ne\emptyset}(-1)^{|J|-1}\mu\left(\bigcap_{i\in J}A_{i}\right) $$ が成り立ちます。これを包除原理(Inclusion-exclusion principle)と呼びます。
証明 証明は $$ \int_{X}\left(1-\prod_{i=1}^{n}(1-1_{A_{i}})\right)d\mu $$ を二通りに計算することにより求まります。
はじめに愚直に展開してみることにします。 $$ \prod_{i=1}^{n}(1-x_{i})=\sum_{J\subset[n]}(-1)^{|J|}\prod_{i\in J}x_{i} $$ は展開すればわかるので、この$x_{i}$に$1_{A_{i}}$を代入すると、 $$ 1-\prod_{i=1}^{n}(1-1_{A_{i}})=1-\sum_{J\subset[n]}(-1)^{|J|}\prod_{i\in J}1_{A_{i}} =\sum_{J\subset[n];J\ne\emptyset}(-1)^{|J|-1}1_{\bigcap_{i\in J}A_{i}} $$ となります。ここで$1_{A}1_{B}=1_{A\cap B}$を用いました。以上より、 $$ \int_{X}\left(1-\prod_{i=1}^{n}(1-1_{A_{i}})\right)d\mu = \sum_{J\subset[n];J\ne\emptyset}(-1)^{|J|-1}\mu\left(\bigcap_{i\in J}A_{i}\right) $$ がわかります。これで包除原理の右辺が示されました。
次に賢い計算をしましょう。$1-1_{A}=1_{\overline{A}}$なので、 $$ 1-\prod_{i=1}^{n}(1-1_{A_{i}})=1-\prod_{i=1}^{n}1_{\overline{A_{i}}}=1-1_{\bigcap_{i=1}^{n}\overline{A_{i}}} =1_{\overline{\bigcap_{i=1}^{n}\overline{A_{i}}}} =1_{\bigcup_{i=1}^{n}A_{i}}$$ となります。最後にドモルガンの法則を用いました。 よって、 $$ \int_{X}\left(1-\prod_{i=1}^{n}(1-1_{A_{i}})\right)d\mu =\int_{X} 1_{\bigcup_{i=1}^{n}A_{i}}d\mu = \mu\left(\bigcup_{i=1}^{n}A_{i}\right) $$ となります。 これで包除原理の左辺が導かれ、包除原理が示されました。</description>
    </item>
    
    <item>
      <title>ガウス過程に関する文献</title>
      <link>https://yonesuke.github.io/posts/gp-articles/</link>
      <pubDate>Thu, 06 May 2021 12:53:12 +0900</pubDate>
      
      <guid>https://yonesuke.github.io/posts/gp-articles/</guid>
      <description>ガウス過程とその機械学習への応用に関する文献はたくさんあります。ここで特に有用だと思ったものを紹介していきます。
ガウス過程全般   ガウス過程と機械学習
ガウス過程と機械学習に関する和書です。非常にわかりやすい本でこの本を読めば一通りの実装はできるようになると思います。一冊目としてはこの本で間違いない気がします。
  Gaussian Processes for Machine Learning
ガウス過程と機械学習への適用に関する代表的な本だと思います。PDFはオンラインで読むことができます。
  ガウス過程の数学的な基礎に関する文献   Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences
ガウス過程はカーネル法と切っても切り離せない関係にあります。この論文ではカーネル法との関係に関する結果を簡潔にまとめていて非常に参考になります。例えばRBFカーネルによって生成されるサンプルの関数が確率1で$C^{\infty}$級のなめらかな関数になることはよく知られていますが、その証明の流れもこの論文を読めばわかります。
  Reproducing Kernel Hilbert Spaces in Probability and Statistics
再生核ヒルベルト空間(RKHS)に関する本です。ガウス過程によって出力される関数が属する空間について議論する際にRKHSが出てきます。この本ではRKHSに関する議論やそのガウス過程との関係についても議論されています。この本の一番最後にカーネル関数とその対応するRKHSの具体例が27個載っていて圧巻です。
  補助変数法 データが$N$個あるときにガウス過程回帰を行うと、データ数に応じた逆行列計算が必要で$O(N^{3})$の計算量がかかってしまいます。 データ数が非常に多くなったときにはこの計算量は現実的ではないので補助変数法と呼ばれるものを用いて計算量を削減する試みが行われています。
  A Unifying View of Sparse Approximate Gaussian Process Regression
2005年に出た論文ですが、その時までに出ていた補助変数法の様々な手法をまとめた論文になっています。上で紹介した「ガウス過程と機械学習」ではこの中のFITCと呼ばれる方法が紹介されています。
  Gaussian processes for Big data
変分ベイズ法を用いてガウス過程回帰を行う手法についてまとまった論文です。補助変数の配置などを含めたハイパーパラメーターの最適化が可能になります。
  深層学習との関係   Deep Neural Networks as Gaussian Processes</description>
    </item>
    
    <item>
      <title>LaTeXの設定</title>
      <link>https://yonesuke.github.io/posts/latex-setup/</link>
      <pubDate>Wed, 05 May 2021 18:46:29 +0900</pubDate>
      
      <guid>https://yonesuke.github.io/posts/latex-setup/</guid>
      <description>$\LaTeX$で文章を書くときによく行う設定をまとめておきます。
Overleaf  Overleafで日本語で文章を書く場合は次のlatexmkrcというファイルをおいておきます。 $latex = &amp;#39;platex&amp;#39;; $bibtex = &amp;#39;pbibtex&amp;#39;; $dvipdf = &amp;#39;dvipdfmx %O -o %D %S&amp;#39;; $makeindex = &amp;#39;mendex -U %O -o %D %S&amp;#39;; $pdf_mode = 3; さらにCompilerはLaTeXにしておきましょう。
  Beamer  LaTeXでスライド生成する際に使われるbeamerです。テーマがたくさんあるので好みのものを選ぶと良いと思います。特にmetropolisとfocusというテーマが気に入っています。 \documentclass[dvipdfmx]{beamer} \usepackage{bxdpx-beamer} \usepackage{pxjahyper} \usepackage{minijs} \usetheme[numbering=fraction,block=fill,progressbar=frametitle]{metropolis} \usefonttheme{professionalfonts} \usepackage{appendixnumberbeamer} Appendixに移行する際の区切りのページには次を書くと便利です。
% スライド終わり \appendix \begin{frame}[standout] APPENDIX \end{frame} % アペンディクスはじまり % \begin{frame} % ...   便利Package   hyperref 次のオプションとともに呼ぶと便利です。
\usepackage[colorlinks=true,linkcolor=magenta,citecolor=magenta,breaklinks=true]{hyperref} 特にbreaklinks=trueはリンクを改行してくれるので重宝します。リンクの色は好みに合わせて変えてください。
  biblatex 次のオプションとともに呼ぶとPR系の論文のように参考文献を表示してくれます。
\usepackage[style=phys,articletitle=true,biblabel=brackets,chaptertitle=false,pageranges=false,doi=false]{biblatex} % bibファイルの読み込み \addbibresource{main.</description>
    </item>
    
    <item>
      <title>安定分布に従うノイズの生成方法</title>
      <link>https://yonesuke.github.io/posts/stable_simulations/</link>
      <pubDate>Wed, 21 Apr 2021 20:58:21 +0900</pubDate>
      
      <guid>https://yonesuke.github.io/posts/stable_simulations/</guid>
      <description>安定分布に従うノイズの生成方法について簡単にまとめておきます。 ここでは代表的なWeronの方法を用います。
Weronの方法 はじめに区間$(-\pi/2,\pi/2)$上の一様分布から乱数$V$を、平均$1$の指数分布に従う乱数$W$をそれぞれ生成します。
  $\alpha\ne1$の場合、 $$ \begin{aligned} X=S_{\alpha,\beta}\times\frac{\sin(\alpha(V+B_{\alpha,\beta}))}{(\cos V)^{1/\alpha}}\times\left(\frac{\cos(V-\alpha(V+B_{\alpha,\beta}))}{W}\right)^{(1-\alpha)/\alpha} \end{aligned} $$ を計算します。ここで$B_{\alpha,\beta},S_{\alpha,\beta}$はそれぞれ、 $$\begin{aligned}B_{\alpha,\beta}&amp;amp;=\frac{\arctan(\beta\tan(\pi\alpha/2))}{\alpha},\\S_{\alpha,\beta}&amp;amp;=\left(1+\beta^{2}\tan^{2}(\pi\alpha/2)\right)^{1/(2\alpha)}\end{aligned}$$ です。
  $\alpha=1$の場合には、 $$ X = \frac{2}{\pi}\left[(\frac{\pi}{2}+\beta V)\tan V - \beta\log\left(\frac{\frac{\pi}{2}W\cos V}{\frac{\pi}{2}+\beta V}\right)\right] $$ を計算します。
  これより、$X\sim S(\alpha,\beta,1,0)$なる安定分布ノイズが得られます。 より一般に$S(\alpha,\beta,\gamma,\delta)$に従うノイズがほしければ$\gamma X+\delta$とすれば良いです。
補足 $\beta=0$の場合には$S(\alpha,0,1,0)$に従うノイズの生成式は一つにまとめられて、 $$ X=\frac{\sin(\alpha V)}{(\cos V)^{1/\alpha}}\times\left(\frac{\cos((1-\alpha)V)}{W}\right)^{(1-\alpha)/\alpha} $$ とすればよいです。
この式において更に$\alpha=1$にすれば$X=\tan V$となり、これは平均$0$、$\gamma=1$のCauchy分布に従うノイズの生成方法に一致します。
また、$\alpha=2$の場合には$P,Q\sim U(0,1)$として $$ X=-2\cos\pi P\sqrt{-\log Q} $$ となり、これは平均$0$、分散$2$の正規分布に従うノイズの生成方法であるBox–Muller法に一致します。</description>
    </item>
    
    <item>
      <title>多変量正規分布間のKL距離</title>
      <link>https://yonesuke.github.io/posts/kl-gaussian/</link>
      <pubDate>Mon, 19 Apr 2021 00:32:17 +0900</pubDate>
      
      <guid>https://yonesuke.github.io/posts/kl-gaussian/</guid>
      <description>確率分布の間の&amp;quot;近さ&amp;quot;を測る代表的なものとしてKL距離(Kullback–Leibler divergence)があります。特に多変量正規分布間のKL距離は変分下界を計算する際に登場することもあったりして応用上も重要です。その導出を行います。
準備 平均$\mu$、分散共分散行列$\Sigma$の$N$次元正規分布$\mathcal{N}(u\mid\mu,\Sigma)$の確率密度関数は $$ p(u)=\frac{1}{\sqrt{2\pi}^{N}\sqrt{| \Sigma |}}\exp\left[-\frac{1}{2}(u-\mu)^{\mathsf{T}}\Sigma^{-1}(u-\mu)\right] $$ で与えられます。 また、確率分布$q$に対する確率分布$p$のKL距離は $$ \text{KL}[p || q]=\int p(u)\log\frac{p(u)}{q(u)}du $$ で定義されます。
導出 2つの$N$次元正規分布$p(u)=\mathcal{N}(u \mid \mu _ {1},\Sigma _ {1}),q(u)=\mathcal{N}(u \mid \mu _ {2},\Sigma _ {2})$に対して$\text{KL}[p || q]$を計算します。 $\log$部分を展開すると、 $$ \log\frac{p(u)}{q(u)}=\frac{1}{2}\log\frac{|\Sigma _ {2}|}{|\Sigma _ {1}|} -\frac{1}{2}(u-\mu _ {1})^{\mathsf{T}}\Sigma _ {1}^{-1}(u-\mu _ {1}) + \frac{1}{2}(u-\mu _ {2})^{\mathsf{T}}\Sigma _ {2}^{-1}(u-\mu _ {2}) $$ と3つにわかれるので $$ \begin{aligned} \text{KL}[p || q] = &amp;amp;\frac{1}{2}\log\frac{|\Sigma _ {2}|}{|\Sigma _ {1}|}\int_{\mathbb{R}^{N}}p(u)du \\ &amp;amp; - \frac{1}{2}\int_{\mathbb{R}^{N}}(u-\mu _ {1})^{\mathsf{T}}\Sigma _ {1}^{-1}(u-\mu _ {1})p(u)du \\ &amp;amp; + \frac{1}{2}\int_{\mathbb{R}^{N}}(u-\mu _ {2})^{\mathsf{T}}\Sigma _ {2}^{-1}(u-\mu _ {2}) p(u)du \end{aligned} $$ とできます。各行を計算していきます。</description>
    </item>
    
    <item>
      <title>博士課程1年目を振り返る</title>
      <link>https://yonesuke.github.io/posts/d1/</link>
      <pubDate>Mon, 22 Mar 2021 00:14:18 +0900</pubDate>
      
      <guid>https://yonesuke.github.io/posts/d1/</guid>
      <description>2020年の4月から京都大学大学院情報学研究科に博士課程として入学してから1年が経ちました。 ここに博士課程1年目に起こったことをまとめておきます。 将来博士課程に進学する誰かの参考になれば良いなと思います。
僕は京都大学大学院情報学研究科先端数理科学専攻の非線形物理学講座という研究室に所属しています。 修士までは同じ情報学研究科の数理工学専攻の研究室に所属していて、博士課程から移ってきました。 主にリズム現象に関する研究を行っています。 特にリズム現象を記述する結合振動子系が示す同期転移を、力学系の手法を用いて理論解析をしたり、統計力学の手法を用いて数値計算をしたりしてきました。 最近は流行りに乗っかって機械学習の勉強も少ししようと思っています。
4月 新しい研究室に所属して頑張って研究をするぞ！！と思っていた矢先に新型コロナウイルスの感染拡大とそれに伴う緊急事態宣言が発令されました。 そのため、ずっと家に篭りっきりでした(みなさんもそうだったと思いますが)。 研究室のセミナー等はすべてzoomで行われることになりました。 これまで研究室で研究するタイプの人間で、家では勉強していなかったので、家で勉強とか研究をするのに慣れなくてあまり集中できませんでしたね。。。 あとしょぼい椅子に長時間座ることになって体がバキバキになりました。 椅子を奮発して買ったのですがこれが良かったです。こういうものには投資していくべきだな、と気付かされました。
研究の面では修論の結果を論文にまとめる作業をずっとしていました。 あとガウス過程の勉強をはじめました。 また、TAの業務がちょくちょくありました。貴重な収入源なのでありがたいです。
5月 この頃はずっと学振でしたね、、、辛かったです。 申請書を書くのがまじで向いていないなあ、と実感しました。 研究者たちは科研費を取るためにああいった申請書を書き続けているのだ、と思うと頭が上がりません。
5月の終わり頃に緊急事態宣言が解除されて、この頃からちょくちょく研究室に行くようになりました。
6月 6月のはじめに学振の締め切りがあって肩の荷が下りた感じがしました。 ただ、申請書でいうと民間奨学金の申請と学振を持っていない人対象のRA雇用の申請もあって、 6月の前半も申請書で潰れていた気がします。 (本当は気合を入れたらすぐできることだったと思うんですが、 頭の片隅に申請書がずっとちらついていて研究をしていてもあまり集中ができない感じでした。)
7月 修論の結果を論文にまとめる作業もだいぶ収束してきてarxivにアップロードしました。 (arxivにアップロードするとき、texファイルやらepsファイルやらを一個ずつポチポチしないといけないのはなんとかならないんですかね。。) また、論文をPREに投稿しました。投稿してから毎日のようにstatusのところを眺めていました。
学振も論文も終わったのでずっと積んでいたデスストランディングというゲームを一気に終わらせました。 めっちゃおもろかったです。
8月 色々なことが片付いたので、研究のことを一旦忘れて勉強に全振りしていた気がします。 特に関数解析の勉強を重点的に行いました。 この時期はやるべきことも特になくて平和だった気がします。
9月 9月は日本物理学会とRIMSの力学系研究集会での発表がありました。 あと7月に投稿した論文の査読も帰ってきて8月とは一転急に忙しくなりました。
9月の終わり頃に学振の結果が帰ってきて不採用でした。 もちろん残念だったんですが、思ったほど悲観的ではなかった気がします。 落ちるだろうなあ、と思いながら結果を待つようにしていたのと、 TA・RAやJASSOや民間の奨学金のおかげで死なない程度には生きていけていたからなのかなあ、と自己分析をしていました(笑)
10月 10月からは後期の授業が始まりました。様々なことが引き続きzoomで行われていました。 8月からちょくちょく関数解析を勉強していたおかげで読める(理解できる)論文が少し増えたような気がします。勉強は大事。
この後期から京都外国語大学で非常勤講師として授業を受け持つことになりました。張り切ってnotionでホームページ的なのを作ってみました。 こちらも授業はすべてオンラインでした。学生とのやり取りにはmicrosoftのteamsというサービスが使われていて、 それでオンラインの授業も行いました。 授業をオンラインでするのは初めてだったのですが、やはり学生の顔が見えないのでみんながどれくらい理解しているのかが全然わからなくて 結構難しかったです。「手を挙げる」機能を使って適宜わからないところがないかを学生に聞いてみたりしていました。 授業の準備(授業スライド、演習問題、解説などなど)で半日から一日近く潰れていた気がします。 研究者の方々も毎年のように授業の準備をしているのだ、と思うと頭が上がりません(2回目)。
11月 9月に帰ってきた論文の直しがようやく終わり、PREに投稿し直しました。 今度はめっちゃ返事が早くて、acceptが決まりました。 よく読んでいた雑誌なので通ったのは嬉しかったです。
関数解析の勉強をしたし、neural networkの万能近似定理の証明を読みました。元論文はCybenkoによるものです。 この論文はいい感じの活性化関数を使った3層neural netoworkにおいて、中間層のunit数が無限の極限では任意の連続関数に近づけることができることを証明しています。 せっかく読んだので研究室内で発表することにしました。5人くらい(?)参加してくれて、2週に分けて関数解析の基礎から万能近似定理の証明まで話すことにしました。 駆け足で説明したのでみんながわかってくれたかは分からないです(笑)
この時期はアメリカで大統領選挙が行われて、それに関連して(関連はしてないですが)Strogatz先生がtweetしたことが目に止まりました。 If anyone wants to distract themselves while the votes are being counted, or perhaps just catch up on some lost sleep, have a look at this lecture I gave to students at Cambridge University a few days ago: https://t.</description>
    </item>
    
    <item>
      <title>2020年度 数的理解</title>
      <link>https://yonesuke.github.io/teaching/2020-suutekirikai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yonesuke.github.io/teaching/2020-suutekirikai/</guid>
      <description>授業内容・計画 問題演習を通して、基礎的な数学の知識を身につける演習を行う。特に、SPI試験などを受験する際に必要な数学的知識を身につけ、問題が解けるようになることを目指す。また、問題演習を通して、数学的な考え方や論理的な考え方を身につけることも目指す。
 教科書 『最新最強のSPIクリア問題集』 成美堂出版編集部　著 (成美堂出版)
 スケジュール 水曜4限 (15:40~17:20)
    日付 授業内容 授業スライド 問題演習     第1回 10月7日 オリエンテーション Google スライド      割合 Google スライド 割合 PDF   第2回 10月14日 損益算 Google スライド 損益算 PDF   第3回 10月21日 順序、組み合わせ Google スライド 順序、組み合わせ PDF   第4回 10月28日 確率 Google スライド 確率 PDF   第5回 11月11日 方程式 Google スライド 方程式 PDF   第6回 11月25日 $n$進数 Google スライド $n$進数 PDF   第7回 12月2日 距離と時間と速さ Google スライド 距離と時間と速さ PDF   第8回 12月9日 濃度算 Google スライド 濃度算 PDF   第9回 12月16日 数列 Google スライド 数列 PDF   第10回 12月23日 関数とグラフ Google スライド 関数とグラフ PDF   第11回 1月6日 集合 Google スライド 集合 PDF   第12回 1月13日 論理 Google スライド 論理 PDF   第13回 1月20日 テスト演習と解説1  解答 PDF   第14回 1月27日 テスト演習と解説2  解答 PDF     成績評価   平常点 平常点は60点満点になります。第1回から第12回までの各授業で問題演習を提出した回数に5をかけた数が平常点になります。例えば12回すべての問題演習を提出した方の平常点は60点です。一方で12回のうち9回しか提出出来なかった方の平常点は45点です。</description>
    </item>
    
    <item>
      <title>2021年度 数的理解</title>
      <link>https://yonesuke.github.io/teaching/2021-suutekirikai/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yonesuke.github.io/teaching/2021-suutekirikai/</guid>
      <description>授業内容・計画 問題演習を通して、基礎的な数学の知識を身につける演習を行う。特に、SPI試験などを受験する際に必要な数学的知識を身につけ、問題が解けるようになることを目指す。また、問題演習を通して、数学的な考え方や論理的な考え方を身につけることも目指す。
 教科書 未定
 スケジュール 水曜4限 (15:40~17:20)
    日付 授業内容 授業スライド 問題演習     第1回  オリエンテーション       割合     第2回  損益算     第3回  順序、組み合わせ     第4回  確率     第5回  方程式     第6回  $n$進数     第7回  距離と時間と速さ     第8回  濃度算     第9回  数列     第10回  関数とグラフ     第11回  集合     第12回  論理     第13回  テスト演習と解説1     第14回  テスト演習と解説2       成績評価   平常点 平常点は60点満点になります。第1回から第12回までの各授業で問題演習を提出した回数に5をかけた数が平常点になります。例えば12回すべての問題演習を提出した方の平常点は60点です。一方で12回のうち9回しか提出出来なかった方の平常点は45点です。</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://yonesuke.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yonesuke.github.io/about/</guid>
      <description>Education   Ph.D. student April 2020 -
Nonlinear Physics Division, Department of Applied Mathematical Scienced, Graduate School of Informatics, Kyoto University.
Supervised by Toshio Aoyagi
  M.S. April 2018 - March 2020
Dynamical Systems Group, Department of Applied Mathematics and Physics, Graduate School of Informatics, Kyoto University.
Supervised by Yoshiyuki Y. Yamaguchi
  B.S. April 2014 - March 2018
Department of Informatics and Mathematical Science, Faculty of Engineering, Kyoto University.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>https://yonesuke.github.io/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yonesuke.github.io/research/</guid>
      <description>Keywords Synchronization, Kuramoto model, Critical phenomena, Gaussian process
Publications  R. Yoneda, T. Tatsukawa, and J. Teramae, The lower bound of the network connetivity guaranteeing in-phase synchronization, accepted to Chaos, arXiv: 2104.05954. R. Yoneda, K. Harada, and Y. Y. Yamaguchi, Critical exponents in coupled phase-oscillator models on small-world networks, Phys. Rev. E 102, 062212 (2020), arXiv: 2007.04539. R. Yoneda and Y. Y. Yamaguchi, Classification of bifurcation diagrams in coupled phase-oscillator models with asymmetric natural frequency distributions, J.</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>https://yonesuke.github.io/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yonesuke.github.io/teaching/</guid>
      <description>2021  2021年10月-2022年2月, 数的理解(短) (京都外国語大学・非常勤講師)  ホームページ    2020  2020年10月-2021年2月, 数的理解(短) (京都外国語大学・非常勤講師)  ホームページ ここに作り直しました    Teaching Assistant 2021  2021年4月-8月, 物理学基礎論A (京都大学工学部) 2021年4月-8月, 非線形動力学 (京都大学工学部)  2020  2020年10月-2021年2月, 解析力学 (京都大学工学部) 2020年4月-8月, 基礎数理演習 (京都大学工学部) 2020年4月-8月, 非線形動力学 (京都大学工学部)  2019  2019年10月-2020年2月, 工業数学A1 (京都大学工学部) 2019年4月-8月, 基礎数理演習 (京都大学工学部)  2018   2018年10月-2019年3月, 微分積分学続論II (京都大学工学部)
  2018年4月-8月, 基礎数理演習 (京都大学工学部)
  2018年4月-8月, 工業数学A3 (京都大学工学部)
  </description>
    </item>
    
  </channel>
</rss>
