<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Random Fourier Features | Ryosuke Yoneda</title>
<meta name="keywords" content="">
<meta name="description" content="カーネル法によるリッジ回帰は表現力が高いことが知られており、またその数学的背景の豊かさから多くの研究がなされてきました。 しかし、$n$個のデータ数に対して推論に$\mathcal{O}(n^{3})$の計算量が必要とされるため、計算量を低減させる方法を検討することは非常に重要です。 ここでは、Random Fourier Features 1と呼ばれる方法を紹介します。 実装も行ったがGistにも公開している。
Random Fourier Features Random Fourier Featuresはカーネル関数$k(x,y)\colon\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}$が$x-y$の関数$\phi(x-y)$で表現できる場合に、それをランダムな基底で近似する手法である。キモとなるのはBochnerの定理である。
Theorem &nbsp; &nbsp;[Bochnerの定理] $k(x,y)=\phi(x-y)$が連続な正定値カーネルであるための必要十分条件は$\mathbb{R}^{d}$上の有限非負Borel測度$\mu$があって、 $$ k(x,y)=\int_{\mathbb{R}^{d}}e^{i\omega^{\top}(x-y)}\mathrm{d}\mu(\omega) $$ で表されることである。 適当にスケールすれば$\mu$は確率になり、(存在すれば)$\mathrm{d}\mu(\omega)=p(\omega)\mathrm{d}\omega$と書くことが出来る。 このとき、$k$の値域は実数であるので、 $$ k(x,y)=\mathbb{E}_ {\omega}[\cos(\omega^{\top}(x-y))] $$ 実はこれは$b$を$[0,2\pi)$上の一様乱数として、 $$ 2\mathbb{E}_ {\omega,b}[\cos(\omega^{\top}x&#43;b)\cos(\omega^{\top}y&#43;b)] $$ と一致することがわかる。(加法定理を用いよ)
Proposition &nbsp; &nbsp;[Random Fourier Features] カーネル関数$k(x,y)$が$x-y$の関数で与えられるとき、 $$ k(x,y)=2\mathbb{E}_ {\omega,b}[\cos(\omega^{\top}x&#43;b)\cos(\omega^{\top}y&#43;b)] $$ が成立する。ここで、$\omega$は$k$の確率に従い、$b$は$[0,2\pi)$上の一様分布に従う。 この性質を用いてカーネル関数を近似することを考える。$\omega_{i},b_{i}$をそれぞれの分布に従う乱数として$m$個発生させ、関数$z_{i}(x)=\sqrt{2/m}\cos(\omega_{i}^{\top}x&#43;b_{i})$を構成したとき、 $$ \sum_{i=1}^{m}z_{i}(x)z_{i}(y)\to k(x,y) $$ が$m\to\infty$の極限で大数の法則により収束していく。
Kernel Ridge Regression Random Fourier Featuresを用いてカーネル関数を表現することによってカーネルリッジ回帰の計算量が低減される。
データ$\mathcal{D}=\{(x_{i},y_{i})\}_ {i=1}^{n}$が与えられる場合を考える。入力$x_{i}$を特徴写像$\Phi$で写し、写した先の空間$H$でリッジ回帰をする。 損失関数は $$ L=\sum_{i=1}^{n}[y_{i}-f(x_{i})]^{2}&#43;\lambda||f||^{2}_ {H} $$ となり、これを最小化する$f\in H$を探す。$\lambda||f||^{2}_ {H}$は正則化の項である。 Representation定理により$f$は$\Phi(x_{i})$で展開されることがわかり、色々計算すると損失関数を最小化する$\hat{f}$は $$ \hat{f}(x)=\sum_{i=1}^{n}\hat{\alpha}_{i}k(x_{i},x) $$ となることがわかる。ここで、$\hat{\alpha}=(K&#43;\lambda I_{n})^{-1}y,[K]_{ij}=k(x_{i},x_{j})$である。 $\alpha$の計算に逆行列が含まれるため$\mathcal{O}(n^{3})$の計算量が必要となってしまう。">
<meta name="author" content="Ryosuke Yoneda">
<link rel="canonical" href="https://yonesuke.github.io/posts/random_fourier_feature/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css" integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe&#43;FVUFzPh7U=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://yonesuke.github.io/favicon_io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://yonesuke.github.io/favicon_io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://yonesuke.github.io/favicon_io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://yonesuke.github.io/favicon_io/apple-touch-icon.png">
<link rel="mask-icon" href="https://yonesuke.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" integrity="sha384-Xi8rHCmBmhbuyyhbI88391ZKP2dmfnOl4rT9ZfRI7mLTdk1wblIUnrIq35nqwEvC" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js" integrity="sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>


<link rel="stylesheet" href="https://yonesuke.github.io/css/theoremproof.css">
<meta property="og:title" content="Random Fourier Features" />
<meta property="og:description" content="カーネル法によるリッジ回帰は表現力が高いことが知られており、またその数学的背景の豊かさから多くの研究がなされてきました。 しかし、$n$個のデータ数に対して推論に$\mathcal{O}(n^{3})$の計算量が必要とされるため、計算量を低減させる方法を検討することは非常に重要です。 ここでは、Random Fourier Features 1と呼ばれる方法を紹介します。 実装も行ったがGistにも公開している。
Random Fourier Features Random Fourier Featuresはカーネル関数$k(x,y)\colon\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}$が$x-y$の関数$\phi(x-y)$で表現できる場合に、それをランダムな基底で近似する手法である。キモとなるのはBochnerの定理である。
Theorem &nbsp; &nbsp;[Bochnerの定理] $k(x,y)=\phi(x-y)$が連続な正定値カーネルであるための必要十分条件は$\mathbb{R}^{d}$上の有限非負Borel測度$\mu$があって、 $$ k(x,y)=\int_{\mathbb{R}^{d}}e^{i\omega^{\top}(x-y)}\mathrm{d}\mu(\omega) $$ で表されることである。 適当にスケールすれば$\mu$は確率になり、(存在すれば)$\mathrm{d}\mu(\omega)=p(\omega)\mathrm{d}\omega$と書くことが出来る。 このとき、$k$の値域は実数であるので、 $$ k(x,y)=\mathbb{E}_ {\omega}[\cos(\omega^{\top}(x-y))] $$ 実はこれは$b$を$[0,2\pi)$上の一様乱数として、 $$ 2\mathbb{E}_ {\omega,b}[\cos(\omega^{\top}x&#43;b)\cos(\omega^{\top}y&#43;b)] $$ と一致することがわかる。(加法定理を用いよ)
Proposition &nbsp; &nbsp;[Random Fourier Features] カーネル関数$k(x,y)$が$x-y$の関数で与えられるとき、 $$ k(x,y)=2\mathbb{E}_ {\omega,b}[\cos(\omega^{\top}x&#43;b)\cos(\omega^{\top}y&#43;b)] $$ が成立する。ここで、$\omega$は$k$の確率に従い、$b$は$[0,2\pi)$上の一様分布に従う。 この性質を用いてカーネル関数を近似することを考える。$\omega_{i},b_{i}$をそれぞれの分布に従う乱数として$m$個発生させ、関数$z_{i}(x)=\sqrt{2/m}\cos(\omega_{i}^{\top}x&#43;b_{i})$を構成したとき、 $$ \sum_{i=1}^{m}z_{i}(x)z_{i}(y)\to k(x,y) $$ が$m\to\infty$の極限で大数の法則により収束していく。
Kernel Ridge Regression Random Fourier Featuresを用いてカーネル関数を表現することによってカーネルリッジ回帰の計算量が低減される。
データ$\mathcal{D}=\{(x_{i},y_{i})\}_ {i=1}^{n}$が与えられる場合を考える。入力$x_{i}$を特徴写像$\Phi$で写し、写した先の空間$H$でリッジ回帰をする。 損失関数は $$ L=\sum_{i=1}^{n}[y_{i}-f(x_{i})]^{2}&#43;\lambda||f||^{2}_ {H} $$ となり、これを最小化する$f\in H$を探す。$\lambda||f||^{2}_ {H}$は正則化の項である。 Representation定理により$f$は$\Phi(x_{i})$で展開されることがわかり、色々計算すると損失関数を最小化する$\hat{f}$は $$ \hat{f}(x)=\sum_{i=1}^{n}\hat{\alpha}_{i}k(x_{i},x) $$ となることがわかる。ここで、$\hat{\alpha}=(K&#43;\lambda I_{n})^{-1}y,[K]_{ij}=k(x_{i},x_{j})$である。 $\alpha$の計算に逆行列が含まれるため$\mathcal{O}(n^{3})$の計算量が必要となってしまう。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yonesuke.github.io/posts/random_fourier_feature/" /><meta property="og:image" content="https://yonesuke.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-06T23:34:02+09:00" />
<meta property="article:modified_time" content="2023-01-06T23:34:02+09:00" /><meta property="og:site_name" content="Ryosuke Yoneda" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://yonesuke.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"/>

<meta name="twitter:title" content="Random Fourier Features"/>
<meta name="twitter:description" content="カーネル法によるリッジ回帰は表現力が高いことが知られており、またその数学的背景の豊かさから多くの研究がなされてきました。 しかし、$n$個のデータ数に対して推論に$\mathcal{O}(n^{3})$の計算量が必要とされるため、計算量を低減させる方法を検討することは非常に重要です。 ここでは、Random Fourier Features 1と呼ばれる方法を紹介します。 実装も行ったがGistにも公開している。
Random Fourier Features Random Fourier Featuresはカーネル関数$k(x,y)\colon\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}$が$x-y$の関数$\phi(x-y)$で表現できる場合に、それをランダムな基底で近似する手法である。キモとなるのはBochnerの定理である。
Theorem &nbsp; &nbsp;[Bochnerの定理] $k(x,y)=\phi(x-y)$が連続な正定値カーネルであるための必要十分条件は$\mathbb{R}^{d}$上の有限非負Borel測度$\mu$があって、 $$ k(x,y)=\int_{\mathbb{R}^{d}}e^{i\omega^{\top}(x-y)}\mathrm{d}\mu(\omega) $$ で表されることである。 適当にスケールすれば$\mu$は確率になり、(存在すれば)$\mathrm{d}\mu(\omega)=p(\omega)\mathrm{d}\omega$と書くことが出来る。 このとき、$k$の値域は実数であるので、 $$ k(x,y)=\mathbb{E}_ {\omega}[\cos(\omega^{\top}(x-y))] $$ 実はこれは$b$を$[0,2\pi)$上の一様乱数として、 $$ 2\mathbb{E}_ {\omega,b}[\cos(\omega^{\top}x&#43;b)\cos(\omega^{\top}y&#43;b)] $$ と一致することがわかる。(加法定理を用いよ)
Proposition &nbsp; &nbsp;[Random Fourier Features] カーネル関数$k(x,y)$が$x-y$の関数で与えられるとき、 $$ k(x,y)=2\mathbb{E}_ {\omega,b}[\cos(\omega^{\top}x&#43;b)\cos(\omega^{\top}y&#43;b)] $$ が成立する。ここで、$\omega$は$k$の確率に従い、$b$は$[0,2\pi)$上の一様分布に従う。 この性質を用いてカーネル関数を近似することを考える。$\omega_{i},b_{i}$をそれぞれの分布に従う乱数として$m$個発生させ、関数$z_{i}(x)=\sqrt{2/m}\cos(\omega_{i}^{\top}x&#43;b_{i})$を構成したとき、 $$ \sum_{i=1}^{m}z_{i}(x)z_{i}(y)\to k(x,y) $$ が$m\to\infty$の極限で大数の法則により収束していく。
Kernel Ridge Regression Random Fourier Featuresを用いてカーネル関数を表現することによってカーネルリッジ回帰の計算量が低減される。
データ$\mathcal{D}=\{(x_{i},y_{i})\}_ {i=1}^{n}$が与えられる場合を考える。入力$x_{i}$を特徴写像$\Phi$で写し、写した先の空間$H$でリッジ回帰をする。 損失関数は $$ L=\sum_{i=1}^{n}[y_{i}-f(x_{i})]^{2}&#43;\lambda||f||^{2}_ {H} $$ となり、これを最小化する$f\in H$を探す。$\lambda||f||^{2}_ {H}$は正則化の項である。 Representation定理により$f$は$\Phi(x_{i})$で展開されることがわかり、色々計算すると損失関数を最小化する$\hat{f}$は $$ \hat{f}(x)=\sum_{i=1}^{n}\hat{\alpha}_{i}k(x_{i},x) $$ となることがわかる。ここで、$\hat{\alpha}=(K&#43;\lambda I_{n})^{-1}y,[K]_{ij}=k(x_{i},x_{j})$である。 $\alpha$の計算に逆行列が含まれるため$\mathcal{O}(n^{3})$の計算量が必要となってしまう。"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://yonesuke.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Random Fourier Features",
      "item": "https://yonesuke.github.io/posts/random_fourier_feature/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Random Fourier Features",
  "name": "Random Fourier Features",
  "description": "カーネル法によるリッジ回帰は表現力が高いことが知られており、またその数学的背景の豊かさから多くの研究がなされてきました。 しかし、$n$個のデータ数に対して推論に$\\mathcal{O}(n^{3})$の計算量が必要とされるため、計算量を低減させる方法を検討することは非常に重要です。 ここでは、Random Fourier Features 1と呼ばれる方法を紹介します。 実装も行ったがGistにも公開している。\nRandom Fourier Features Random Fourier Featuresはカーネル関数$k(x,y)\\colon\\mathbb{R}^{d}\\times\\mathbb{R}^{d}\\to\\mathbb{R}$が$x-y$の関数$\\phi(x-y)$で表現できる場合に、それをランダムな基底で近似する手法である。キモとなるのはBochnerの定理である。\nTheorem \u0026nbsp; \u0026nbsp;[Bochnerの定理] $k(x,y)=\\phi(x-y)$が連続な正定値カーネルであるための必要十分条件は$\\mathbb{R}^{d}$上の有限非負Borel測度$\\mu$があって、 $$ k(x,y)=\\int_{\\mathbb{R}^{d}}e^{i\\omega^{\\top}(x-y)}\\mathrm{d}\\mu(\\omega) $$ で表されることである。 適当にスケールすれば$\\mu$は確率になり、(存在すれば)$\\mathrm{d}\\mu(\\omega)=p(\\omega)\\mathrm{d}\\omega$と書くことが出来る。 このとき、$k$の値域は実数であるので、 $$ k(x,y)=\\mathbb{E}_ {\\omega}[\\cos(\\omega^{\\top}(x-y))] $$ 実はこれは$b$を$[0,2\\pi)$上の一様乱数として、 $$ 2\\mathbb{E}_ {\\omega,b}[\\cos(\\omega^{\\top}x+b)\\cos(\\omega^{\\top}y+b)] $$ と一致することがわかる。(加法定理を用いよ)\nProposition \u0026nbsp; \u0026nbsp;[Random Fourier Features] カーネル関数$k(x,y)$が$x-y$の関数で与えられるとき、 $$ k(x,y)=2\\mathbb{E}_ {\\omega,b}[\\cos(\\omega^{\\top}x+b)\\cos(\\omega^{\\top}y+b)] $$ が成立する。ここで、$\\omega$は$k$の確率に従い、$b$は$[0,2\\pi)$上の一様分布に従う。 この性質を用いてカーネル関数を近似することを考える。$\\omega_{i},b_{i}$をそれぞれの分布に従う乱数として$m$個発生させ、関数$z_{i}(x)=\\sqrt{2/m}\\cos(\\omega_{i}^{\\top}x+b_{i})$を構成したとき、 $$ \\sum_{i=1}^{m}z_{i}(x)z_{i}(y)\\to k(x,y) $$ が$m\\to\\infty$の極限で大数の法則により収束していく。\nKernel Ridge Regression Random Fourier Featuresを用いてカーネル関数を表現することによってカーネルリッジ回帰の計算量が低減される。\nデータ$\\mathcal{D}=\\{(x_{i},y_{i})\\}_ {i=1}^{n}$が与えられる場合を考える。入力$x_{i}$を特徴写像$\\Phi$で写し、写した先の空間$H$でリッジ回帰をする。 損失関数は $$ L=\\sum_{i=1}^{n}[y_{i}-f(x_{i})]^{2}+\\lambda||f||^{2}_ {H} $$ となり、これを最小化する$f\\in H$を探す。$\\lambda||f||^{2}_ {H}$は正則化の項である。 Representation定理により$f$は$\\Phi(x_{i})$で展開されることがわかり、色々計算すると損失関数を最小化する$\\hat{f}$は $$ \\hat{f}(x)=\\sum_{i=1}^{n}\\hat{\\alpha}_{i}k(x_{i},x) $$ となることがわかる。ここで、$\\hat{\\alpha}=(K+\\lambda I_{n})^{-1}y,[K]_{ij}=k(x_{i},x_{j})$である。 $\\alpha$の計算に逆行列が含まれるため$\\mathcal{O}(n^{3})$の計算量が必要となってしまう。",
  "keywords": [
    
  ],
  "articleBody": "カーネル法によるリッジ回帰は表現力が高いことが知られており、またその数学的背景の豊かさから多くの研究がなされてきました。 しかし、$n$個のデータ数に対して推論に$\\mathcal{O}(n^{3})$の計算量が必要とされるため、計算量を低減させる方法を検討することは非常に重要です。 ここでは、Random Fourier Features 1と呼ばれる方法を紹介します。 実装も行ったがGistにも公開している。\nRandom Fourier Features Random Fourier Featuresはカーネル関数$k(x,y)\\colon\\mathbb{R}^{d}\\times\\mathbb{R}^{d}\\to\\mathbb{R}$が$x-y$の関数$\\phi(x-y)$で表現できる場合に、それをランダムな基底で近似する手法である。キモとなるのはBochnerの定理である。\nTheorem [Bochnerの定理] $k(x,y)=\\phi(x-y)$が連続な正定値カーネルであるための必要十分条件は$\\mathbb{R}^{d}$上の有限非負Borel測度$\\mu$があって、 $$ k(x,y)=\\int_{\\mathbb{R}^{d}}e^{i\\omega^{\\top}(x-y)}\\mathrm{d}\\mu(\\omega) $$ で表されることである。 適当にスケールすれば$\\mu$は確率になり、(存在すれば)$\\mathrm{d}\\mu(\\omega)=p(\\omega)\\mathrm{d}\\omega$と書くことが出来る。 このとき、$k$の値域は実数であるので、 $$ k(x,y)=\\mathbb{E}_ {\\omega}[\\cos(\\omega^{\\top}(x-y))] $$ 実はこれは$b$を$[0,2\\pi)$上の一様乱数として、 $$ 2\\mathbb{E}_ {\\omega,b}[\\cos(\\omega^{\\top}x+b)\\cos(\\omega^{\\top}y+b)] $$ と一致することがわかる。(加法定理を用いよ)\nProposition [Random Fourier Features] カーネル関数$k(x,y)$が$x-y$の関数で与えられるとき、 $$ k(x,y)=2\\mathbb{E}_ {\\omega,b}[\\cos(\\omega^{\\top}x+b)\\cos(\\omega^{\\top}y+b)] $$ が成立する。ここで、$\\omega$は$k$の確率に従い、$b$は$[0,2\\pi)$上の一様分布に従う。 この性質を用いてカーネル関数を近似することを考える。$\\omega_{i},b_{i}$をそれぞれの分布に従う乱数として$m$個発生させ、関数$z_{i}(x)=\\sqrt{2/m}\\cos(\\omega_{i}^{\\top}x+b_{i})$を構成したとき、 $$ \\sum_{i=1}^{m}z_{i}(x)z_{i}(y)\\to k(x,y) $$ が$m\\to\\infty$の極限で大数の法則により収束していく。\nKernel Ridge Regression Random Fourier Featuresを用いてカーネル関数を表現することによってカーネルリッジ回帰の計算量が低減される。\nデータ$\\mathcal{D}=\\{(x_{i},y_{i})\\}_ {i=1}^{n}$が与えられる場合を考える。入力$x_{i}$を特徴写像$\\Phi$で写し、写した先の空間$H$でリッジ回帰をする。 損失関数は $$ L=\\sum_{i=1}^{n}[y_{i}-f(x_{i})]^{2}+\\lambda||f||^{2}_ {H} $$ となり、これを最小化する$f\\in H$を探す。$\\lambda||f||^{2}_ {H}$は正則化の項である。 Representation定理により$f$は$\\Phi(x_{i})$で展開されることがわかり、色々計算すると損失関数を最小化する$\\hat{f}$は $$ \\hat{f}(x)=\\sum_{i=1}^{n}\\hat{\\alpha}_{i}k(x_{i},x) $$ となることがわかる。ここで、$\\hat{\\alpha}=(K+\\lambda I_{n})^{-1}y,[K]_{ij}=k(x_{i},x_{j})$である。 $\\alpha$の計算に逆行列が含まれるため$\\mathcal{O}(n^{3})$の計算量が必要となってしまう。\nここで、Random Fourier Featuresを用いてカーネル関数を近似することを考える。 共分散行列は$[Z]_{ij}=z_{j}(x_{i})$によって$K=ZZ^{\\top}$で展開されるので、 $$ \\begin{align*} \\hat{f}(x)=\u0026\\sum_{i=1}^{n}\\sum_{j=1}^{m}[(K+\\lambda I_{n})^{-1}y]_{i}z_{j}(x_{i})z_{j}(x)\\\\ =\u0026\\sum_{i=1}^{n}\\sum_{j=1}^{m}\\left[\\left(ZZ^{\\top}+\\lambda I_{n}\\right)^{-1}y\\right]_{i}[Z]_{ij}z_{j}(x)\\\\ =\u0026\\sum_{j=1}^{m}\\left[Z^{\\top}\\left(ZZ^{\\top}+\\lambda I_{n}\\right)^{-1}y\\right]_{j}z_{j}(x) \\end{align*} $$ ここでWoodburyの公式から$Z^{\\top}(ZZ^{\\top}+\\lambda I_{n})^{-1}=(Z^{\\top}Z+\\lambda I_{m})^{-1}Z^{\\top}$となる 2 ので、 $$ \\hat{f}(x)=\\sum_{j=1}^{m}\\left[\\left(Z^{\\top}Z+\\lambda I_{m}\\right)^{-1}Z^{\\top}y\\right]_{j}z_{j}(x) $$ で得られる。$Z^{\\top}Z$の計算に$\\mathcal{O}(m^{2}n)$、$Z^{\\top}Z+\\lambda I_{m}$の逆行列計算に$\\mathcal{O}(m^{3})$になるので、$m\\ll n$ならば計算量は$\\mathcal{O}(m^{2}n)$に軽減される。\nImplementation ここではJAXを用いた実装を行う。はじめにカーネル関数のクラスを定義する。 ただし、$k\\colon\\mathbb{R}^{1}\\times\\mathbb{R}^{1}\\to\\mathbb{R}$のものを仮定する。 cov_mat関数は共分散行列を計算する関数である。jax.vmapを使って効率よく計算している。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import jax.numpy as jnp from jax import random, vmap, scipy import matplotlib.pyplot as plt class Kernel: def __init__(self): pass def covariance(self, x1, x2): raise NotImplementedError def cov_mat(self, xs, xs2=None): if xs2 is None: return vmap(lambda x: vmap(lambda y: self.covariance(x, y))(xs))(xs) else: return vmap(lambda x: vmap(lambda y: self.covariance(x, y))(xs2))(xs) これをもとにRBFカーネルとRandom Fourier Featuresを用いた近似カーネルを定義する。 RBFカーネルは $$ k(x,y)=\\exp\\left(-\\frac{(x-y)^{2}}{2\\sigma^{2}}\\right) $$ で定義され、Random Fourier Featuresの確率は$\\mu\\sim\\mathcal{N}(0,1/\\sigma^{2})$になる。 Random Fourier Featuresのスケールは$k(x,x)=1$なるようにすればよいが、RBFカーネルは最初からこれを満たしていることに注意する。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class RadialBasisFunction(Kernel): def __init__(self, sigma): super().__init__() self.sigma = sigma def covariance(self, x1, x2): return jnp.exp(-jnp.sum((x1 - x2) ** 2) / (2 * self.sigma ** 2)) class RandomFourierFeature(Kernel): def __init__(self, n_feature, sigma, seed): super().__init__() self.n_feature = n_feature self.sigma = sigma key_w = random.PRNGKey(seed) self.w = random.normal(key_w, (n_feature,)) / sigma key_b = random.split(key_w, 1) self.b = random.uniform(key_b, (n_feature,)) * 2 * jnp.pi def z(self, x): return jnp.sqrt(2 / self.n_feature) * jnp.cos(self.w * x + self.b) def covariance(self, x1, x2): return jnp.dot(self.z(x1), self.z(x2)) カーネル関数を比較してみよう。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 xs = jnp.arange(-2.0, 2.0, 0.01) sigma = 0.5 plt.figure(figsize=(24, 6)) plt.rcParams[\"font.size\"] = 20 plt.subplot(1, 3, 1) rbf = RadialBasisFunction(sigma) rbf_mat = rbf.cov_mat(xs) plt.matshow(rbf_mat, fignum=0, extent=(-2, 2, -2, 2)) plt.title(\"RBF\") plt.colorbar() plt.subplot(1, 3, 2) n_feature = 100 rff = RandomFourierFeature(n_feature, sigma, 0) rff_mat = rff.cov_mat(xs) plt.matshow(rff_mat, fignum=0, extent=(-2, 2, -2, 2)) plt.title(f\"RFF, n_feature={n_feature}\") plt.colorbar() plt.subplot(1, 3, 3) n_feature = 10000 rff = RandomFourierFeature(n_feature, sigma, 0) rff_mat = rff.cov_mat(xs) plt.matshow(rff_mat, fignum=0, extent=(-2, 2, -2, 2)) plt.title(f\"RFF, n_feature={n_feature}\") plt.colorbar() 特徴写像を$10^4$個も使ってみると、RBFカーネルとほぼ同じになっていることがわかる。\n最後にカーネルリッジ回帰のクラスを定義する。 Random Fourier Featuresか否かでpredict関数を分けている。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class KernelRidgeRegression: def __init__(self, kernel: Kernel, alpha): self.kernel = kernel self.alpha = alpha def fit(self, xs_data, ys_data): self.xs_data = xs_data self.ys_data = ys_data self.K_data = self.kernel.cov_mat(xs_data) if self.kernel.__class__.__name__ == \"RandomFourierFeature\": Z = vmap(self.kernel.z)(xs_data) self.coeffs_rff = scipy.linalg.solve(Z.T @ Z + self.alpha * jnp.eye(self.kernel.n_feature), Z.T @ ys_data) else: self.coeffs = scipy.linalg.solve(self.K_data + self.alpha * jnp.eye(len(xs_data)), ys_data) def predict(self, xs_infer): if self.kernel.__class__.__name__ == \"RandomFourierFeature\": Z = vmap(self.kernel.z)(xs_infer) return Z @ self.coeffs_rff else: K_infer = self.kernel.cov_mat(xs_infer, self.xs_data) return K_infer @ self.coeffs 実際に回帰を行ってみよう。$10^4$個のデータを$x\\mapsto\\sin(2\\pi x)$の関数にノイズを加えたもので生成する。\n1 2 3 4 n_data = 10**4 true_fn = lambda x: jnp.sin(2 * jnp.pi * x) xs_data = random.uniform(random.PRNGKey(0), (n_data,)) ys_data = true_fn(xs_data) + random.normal(random.PRNGKey(1), (n_data,)) * 0.1 正則化のパラメータは$\\lambda=10^{-3}$、カーネルのパラメータは$\\sigma=0.5$とする。 また、Random Fourier Featuresの特徴写像は$100$個とする。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 sigma = 0.5 alpha = 10**-3 n_feature = 100 xs_infer = jnp.arange(-0.1, 1.1, 0.01) # rbf rbf = RadialBasisFunction(sigma) rbf_regression = KernelRidgeRegression(rbf, alpha) rbf_regression.fit(xs_data, ys_data) ys_infer_rbf = rbf_regression.predict(xs_infer) # rff rff = RandomFourierFeature(n_feature, sigma, 0) rff_regression = KernelRidgeRegression(rff, alpha) rff_regression.fit(xs_data, ys_data) ys_infer_rff = rff_regression.predict(xs_infer) # plot plt.figure(figsize=(12, 6)) plt.rcParams[\"font.size\"] = 20 plt.xlim(-0.1, 1.1) plt.scatter(xs_data, ys_data, s=0.1, alpha=0.2) plt.plot(xs_infer, true_fn(xs_infer), c=\"tab:blue\", label=\"true\", lw=1, ls=\"dashed\") plt.plot(xs_infer, ys_infer_rbf, c=\"tab:orange\", label=\"RBF\", lw=2) plt.plot(xs_infer, ys_infer_rff, c=\"tab:green\", label=\"RFF\", lw=2) plt.legend() いずれの手法も関数を回帰できていることを確認できた。 次に、データ数に対する計算時間の比較を行ってみる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import time times_rbf, times_rff = [], [] for n_data in [10**2, 10**3, 10**4, 10**5]: xs_data = random.uniform(random.PRNGKey(0), (n_data,)) ys_data = true_fn(xs_data) + random.normal(random.PRNGKey(1), (n_data,)) * 0.1 # rbf start_rbf = time.perf_counter() rbf = RadialBasisFunction(sigma) rbf_regression = KernelRidgeRegression(rbf, alpha) rbf_regression.fit(xs_data, ys_data) ys_infer_rbf = rbf_regression.predict(xs_infer) end_rbf = time.perf_counter() times_rbf.append(end_rbf - start_rbf) # rff start_rff = time.perf_counter() rff = RandomFourierFeature(n_feature, sigma, 0) rff_regression = KernelRidgeRegression(rff, alpha) rff_regression.fit(xs_data, ys_data) ys_infer_rff = rff_regression.predict(xs_infer) end_rff = time.perf_counter() times_rff.append(end_rff - start_rff) 表にまとめると次のようになる。Random Fourier Featuresの方が計算時間が短いことがわかる。 これは一回だけの計測時間なので本当は複数回計測して平均を取った方が良いが、今回は省略する。 あとデータ数をより増やして理論予測される計算量のスケールに一致するかを比較する必要もあるが、今回は省略する。\n#data RBF RFF $100$ 0.0351[s] 0.0234[s] $1000$ 0.0361[s] 0.0059[s] $10000$ 1.8547[s] 0.0489[s] $20000$ 11.0161[s] 0.1733[s] $30000$ 34.6534[s] 0.4661[s] A. Rahimi, and B. Recht, “Random features for large-scale kernel machines.” Advances in neural information processing systems 20 (2007). [📁 PDF] ↩︎\nこの式自体の証明はWoodburyの公式を用いるまでもなく$Z^{\\top}(ZZ^{\\top}+\\lambda I_{n})=(Z^{\\top}Z+\\lambda I_{m})Z^{\\top}$からわかる。 ↩︎\n",
  "wordCount" : "766",
  "inLanguage": "en",
  "datePublished": "2023-01-06T23:34:02+09:00",
  "dateModified": "2023-01-06T23:34:02+09:00",
  "author":{
    "@type": "Person",
    "name": "Ryosuke Yoneda"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yonesuke.github.io/posts/random_fourier_feature/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Ryosuke Yoneda",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yonesuke.github.io/favicon_io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://yonesuke.github.io" accesskey="h" title="Ryosuke Yoneda&#39;s Homepage (Alt + H)">
                <img src="https://yonesuke.github.io/favicon_io/apple-touch-icon.png" alt="" aria-label="logo"
                    height="35">Ryosuke Yoneda&#39;s Homepage</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://yonesuke.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://yonesuke.github.io/research" title="Research">
                    <span>Research</span>
                </a>
            </li>
            <li>
                <a href="https://yonesuke.github.io/teaching" title="Teaching">
                    <span>Teaching</span>
                </a>
            </li>
            <li>
                <a href="https://yonesuke.github.io/books_codes" title="Books &amp; Codes">
                    <span>Books &amp; Codes</span>
                </a>
            </li>
            <li>
                <a href="https://yonesuke.github.io/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://yonesuke.github.io">Home</a>&nbsp;»&nbsp;<a href="https://yonesuke.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      Random Fourier Features
    </h1>
    <div class="post-meta">&lt;span title=&#39;2023-01-06 23:34:02 &#43;0900 JST&#39;&gt;January 6, 2023&lt;/span&gt;&amp;nbsp;·&amp;nbsp;4 min&amp;nbsp;·&amp;nbsp;766 words&amp;nbsp;·&amp;nbsp;Ryosuke Yoneda

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#random-fourier-features">Random Fourier Features</a></li>
    <li><a href="#kernel-ridge-regression">Kernel Ridge Regression</a></li>
    <li><a href="#implementation">Implementation</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><p>カーネル法によるリッジ回帰は表現力が高いことが知られており、またその数学的背景の豊かさから多くの研究がなされてきました。
しかし、$n$個のデータ数に対して推論に$\mathcal{O}(n^{3})$の計算量が必要とされるため、計算量を低減させる方法を検討することは非常に重要です。
ここでは、Random Fourier Features <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>と呼ばれる方法を紹介します。
実装も行ったが<a href="https://gist.github.com/yonesuke/ebc5a69d270cf2cbc559ce228370f910">Gist</a>にも公開している。</p>
<h2 id="random-fourier-features">Random Fourier Features<a hidden class="anchor" aria-hidden="true" href="#random-fourier-features">#</a></h2>
<p>Random Fourier Featuresはカーネル関数$k(x,y)\colon\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}$が$x-y$の関数$\phi(x-y)$で表現できる場合に、それをランダムな基底で近似する手法である。キモとなるのはBochnerの定理である。</p>
<div class="thmlike">
	<div class="thmheader">
		<span class="thmtype">
			
				Theorem
			
			&nbsp;
		</span>
		 &nbsp;[Bochnerの定理] 
	</div>
	<div class="thmbody">$k(x,y)=\phi(x-y)$が連続な正定値カーネルであるための必要十分条件は$\mathbb{R}^{d}$上の有限非負Borel測度$\mu$があって、
$$
k(x,y)=\int_{\mathbb{R}^{d}}e^{i\omega^{\top}(x-y)}\mathrm{d}\mu(\omega)
$$
で表されることである。</div>
</div>
<p>適当にスケールすれば$\mu$は確率になり、(存在すれば)$\mathrm{d}\mu(\omega)=p(\omega)\mathrm{d}\omega$と書くことが出来る。
このとき、$k$の値域は実数であるので、
$$
k(x,y)=\mathbb{E}_ {\omega}[\cos(\omega^{\top}(x-y))]
$$
実はこれは$b$を$[0,2\pi)$上の一様乱数として、
$$
2\mathbb{E}_ {\omega,b}[\cos(\omega^{\top}x+b)\cos(\omega^{\top}y+b)]
$$
と一致することがわかる。(加法定理を用いよ)</p>
<div class="thmlike">
	<div class="thmheader">
		<span class="thmtype">
			
				Proposition
			
			&nbsp;
		</span>
		 &nbsp;[Random Fourier Features] 
	</div>
	<div class="thmbody">カーネル関数$k(x,y)$が$x-y$の関数で与えられるとき、
$$
k(x,y)=2\mathbb{E}_ {\omega,b}[\cos(\omega^{\top}x+b)\cos(\omega^{\top}y+b)]
$$
が成立する。ここで、$\omega$は$k$の確率に従い、$b$は$[0,2\pi)$上の一様分布に従う。</div>
</div>
<p>この性質を用いてカーネル関数を近似することを考える。$\omega_{i},b_{i}$をそれぞれの分布に従う乱数として$m$個発生させ、関数$z_{i}(x)=\sqrt{2/m}\cos(\omega_{i}^{\top}x+b_{i})$を構成したとき、
$$
\sum_{i=1}^{m}z_{i}(x)z_{i}(y)\to k(x,y)
$$
が$m\to\infty$の極限で大数の法則により収束していく。</p>
<h2 id="kernel-ridge-regression">Kernel Ridge Regression<a hidden class="anchor" aria-hidden="true" href="#kernel-ridge-regression">#</a></h2>
<p>Random Fourier Featuresを用いてカーネル関数を表現することによってカーネルリッジ回帰の計算量が低減される。</p>
<p>データ$\mathcal{D}=\{(x_{i},y_{i})\}_ {i=1}^{n}$が与えられる場合を考える。入力$x_{i}$を特徴写像$\Phi$で写し、写した先の空間$H$でリッジ回帰をする。
損失関数は
$$
L=\sum_{i=1}^{n}[y_{i}-f(x_{i})]^{2}+\lambda||f||^{2}_ {H}
$$
となり、これを最小化する$f\in H$を探す。$\lambda||f||^{2}_ {H}$は正則化の項である。
Representation定理により$f$は$\Phi(x_{i})$で展開されることがわかり、色々計算すると損失関数を最小化する$\hat{f}$は
$$
\hat{f}(x)=\sum_{i=1}^{n}\hat{\alpha}_{i}k(x_{i},x)
$$
となることがわかる。ここで、$\hat{\alpha}=(K+\lambda I_{n})^{-1}y,[K]_{ij}=k(x_{i},x_{j})$である。
$\alpha$の計算に逆行列が含まれるため$\mathcal{O}(n^{3})$の計算量が必要となってしまう。</p>
<p>ここで、Random Fourier Featuresを用いてカーネル関数を近似することを考える。
共分散行列は$[Z]_{ij}=z_{j}(x_{i})$によって$K=ZZ^{\top}$で展開されるので、
$$
\begin{align*}
\hat{f}(x)=&amp;\sum_{i=1}^{n}\sum_{j=1}^{m}[(K+\lambda I_{n})^{-1}y]_{i}z_{j}(x_{i})z_{j}(x)\\
=&amp;\sum_{i=1}^{n}\sum_{j=1}^{m}\left[\left(ZZ^{\top}+\lambda I_{n}\right)^{-1}y\right]_{i}[Z]_{ij}z_{j}(x)\\
=&amp;\sum_{j=1}^{m}\left[Z^{\top}\left(ZZ^{\top}+\lambda I_{n}\right)^{-1}y\right]_{j}z_{j}(x)
\end{align*}
$$
ここでWoodburyの公式から$Z^{\top}(ZZ^{\top}+\lambda I_{n})^{-1}=(Z^{\top}Z+\lambda I_{m})^{-1}Z^{\top}$となる <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> ので、
$$
\hat{f}(x)=\sum_{j=1}^{m}\left[\left(Z^{\top}Z+\lambda I_{m}\right)^{-1}Z^{\top}y\right]_{j}z_{j}(x)
$$
で得られる。$Z^{\top}Z$の計算に$\mathcal{O}(m^{2}n)$、$Z^{\top}Z+\lambda I_{m}$の逆行列計算に$\mathcal{O}(m^{3})$になるので、$m\ll n$ならば計算量は$\mathcal{O}(m^{2}n)$に軽減される。</p>
<h2 id="implementation">Implementation<a hidden class="anchor" aria-hidden="true" href="#implementation">#</a></h2>
<p>ここではJAXを用いた実装を行う。はじめにカーネル関数のクラスを定義する。
ただし、$k\colon\mathbb{R}^{1}\times\mathbb{R}^{1}\to\mathbb{R}$のものを仮定する。
<code>cov_mat</code>関数は共分散行列を計算する関数である。<code>jax.vmap</code>を使って効率よく計算している。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span><span class="p">,</span> <span class="n">vmap</span><span class="p">,</span> <span class="n">scipy</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Kernel</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">pass</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">cov_mat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">xs2</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">xs2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))(</span><span class="n">xs</span><span class="p">))(</span><span class="n">xs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">vmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">covariance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))(</span><span class="n">xs2</span><span class="p">))(</span><span class="n">xs</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>これをもとにRBFカーネルとRandom Fourier Featuresを用いた近似カーネルを定義する。
RBFカーネルは
$$
k(x,y)=\exp\left(-\frac{(x-y)^{2}}{2\sigma^{2}}\right)
$$
で定義され、Random Fourier Featuresの確率は$\mu\sim\mathcal{N}(0,1/\sigma^{2})$になる。
Random Fourier Featuresのスケールは$k(x,x)=1$なるようにすればよいが、RBFカーネルは最初からこれを満たしていることに注意する。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">RadialBasisFunction</span><span class="p">(</span><span class="n">Kernel</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x1</span> <span class="o">-</span> <span class="n">x2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">RandomFourierFeature</span><span class="p">(</span><span class="n">Kernel</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_feature</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">n_feature</span> <span class="o">=</span> <span class="n">n_feature</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
</span></span><span class="line"><span class="cl">        <span class="n">key_w</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key_w</span><span class="p">,</span> <span class="p">(</span><span class="n">n_feature</span><span class="p">,))</span> <span class="o">/</span> <span class="n">sigma</span>
</span></span><span class="line"><span class="cl">        <span class="n">key_b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key_w</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">key_b</span><span class="p">,</span> <span class="p">(</span><span class="n">n_feature</span><span class="p">,))</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pi</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">z</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_feature</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">(</span><span class="n">x1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">z</span><span class="p">(</span><span class="n">x2</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>カーネル関数を比較してみよう。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">xs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&#34;font.size&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">20</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rbf</span> <span class="o">=</span> <span class="n">RadialBasisFunction</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rbf_mat</span> <span class="o">=</span> <span class="n">rbf</span><span class="o">.</span><span class="n">cov_mat</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">rbf_mat</span><span class="p">,</span> <span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;RBF&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">n_feature</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl"><span class="n">rff</span> <span class="o">=</span> <span class="n">RandomFourierFeature</span><span class="p">(</span><span class="n">n_feature</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rff_mat</span> <span class="o">=</span> <span class="n">rff</span><span class="o">.</span><span class="n">cov_mat</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">rff_mat</span><span class="p">,</span> <span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;RFF, n_feature=</span><span class="si">{</span><span class="n">n_feature</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">n_feature</span> <span class="o">=</span> <span class="mi">10000</span>
</span></span><span class="line"><span class="cl"><span class="n">rff</span> <span class="o">=</span> <span class="n">RandomFourierFeature</span><span class="p">(</span><span class="n">n_feature</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rff_mat</span> <span class="o">=</span> <span class="n">rff</span><span class="o">.</span><span class="n">cov_mat</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">rff_mat</span><span class="p">,</span> <span class="n">fignum</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;RFF, n_feature=</span><span class="si">{</span><span class="n">n_feature</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="rbf_rff.png" alt=""  />
</p>
<p>特徴写像を$10^4$個も使ってみると、RBFカーネルとほぼ同じになっていることがわかる。</p>
<p>最後にカーネルリッジ回帰のクラスを定義する。
Random Fourier Featuresか否かで<code>predict</code>関数を分けている。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">KernelRidgeRegression</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="p">:</span> <span class="n">Kernel</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_data</span><span class="p">,</span> <span class="n">ys_data</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">xs_data</span> <span class="o">=</span> <span class="n">xs_data</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ys_data</span> <span class="o">=</span> <span class="n">ys_data</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">K_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">cov_mat</span><span class="p">(</span><span class="n">xs_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;RandomFourierFeature&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">Z</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">z</span><span class="p">)(</span><span class="n">xs_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_rff</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">Z</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">n_feature</span><span class="p">),</span> <span class="n">Z</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">ys_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">coeffs</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">K_data</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs_data</span><span class="p">)),</span> <span class="n">ys_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs_infer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;RandomFourierFeature&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">Z</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">z</span><span class="p">)(</span><span class="n">xs_infer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">Z</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_rff</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">K_infer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">cov_mat</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">xs_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">K_infer</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>実際に回帰を行ってみよう。$10^4$個のデータを$x\mapsto\sin(2\pi x)$の関数にノイズを加えたもので生成する。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">n_data</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="mi">4</span>
</span></span><span class="line"><span class="cl"><span class="n">true_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">xs_data</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">n_data</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl"><span class="n">ys_data</span> <span class="o">=</span> <span class="n">true_fn</span><span class="p">(</span><span class="n">xs_data</span><span class="p">)</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">n_data</span><span class="p">,))</span> <span class="o">*</span> <span class="mf">0.1</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>正則化のパラメータは$\lambda=10^{-3}$、カーネルのパラメータは$\sigma=0.5$とする。
また、Random Fourier Featuresの特徴写像は$100$個とする。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl"><span class="n">alpha</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**-</span><span class="mi">3</span>
</span></span><span class="line"><span class="cl"><span class="n">n_feature</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl"><span class="n">xs_infer</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># rbf</span>
</span></span><span class="line"><span class="cl"><span class="n">rbf</span> <span class="o">=</span> <span class="n">RadialBasisFunction</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rbf_regression</span> <span class="o">=</span> <span class="n">KernelRidgeRegression</span><span class="p">(</span><span class="n">rbf</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rbf_regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xs_data</span><span class="p">,</span> <span class="n">ys_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ys_infer_rbf</span> <span class="o">=</span> <span class="n">rbf_regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># rff</span>
</span></span><span class="line"><span class="cl"><span class="n">rff</span> <span class="o">=</span> <span class="n">RandomFourierFeature</span><span class="p">(</span><span class="n">n_feature</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rff_regression</span> <span class="o">=</span> <span class="n">KernelRidgeRegression</span><span class="p">(</span><span class="n">rff</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rff_regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xs_data</span><span class="p">,</span> <span class="n">ys_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">ys_infer_rff</span> <span class="o">=</span> <span class="n">rff_regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># plot</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&#34;font.size&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">20</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xs_data</span><span class="p">,</span> <span class="n">ys_data</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">,</span> <span class="n">true_fn</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s2">&#34;tab:blue&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;true&#34;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&#34;dashed&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">,</span> <span class="n">ys_infer_rbf</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&#34;tab:orange&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;RBF&#34;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">,</span> <span class="n">ys_infer_rff</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&#34;tab:green&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;RFF&#34;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><img loading="lazy" src="rbf_rff_regression.png" alt=""  />
</p>
<p>いずれの手法も関数を回帰できていることを確認できた。
次に、データ数に対する計算時間の比較を行ってみる。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">time</span>
</span></span><span class="line"><span class="cl"><span class="n">times_rbf</span><span class="p">,</span> <span class="n">times_rff</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">n_data</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="o">**</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="o">**</span><span class="mi">5</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">    <span class="n">xs_data</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">n_data</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl">    <span class="n">ys_data</span> <span class="o">=</span> <span class="n">true_fn</span><span class="p">(</span><span class="n">xs_data</span><span class="p">)</span> <span class="o">+</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">n_data</span><span class="p">,))</span> <span class="o">*</span> <span class="mf">0.1</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># rbf</span>
</span></span><span class="line"><span class="cl">    <span class="n">start_rbf</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">rbf</span> <span class="o">=</span> <span class="n">RadialBasisFunction</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">rbf_regression</span> <span class="o">=</span> <span class="n">KernelRidgeRegression</span><span class="p">(</span><span class="n">rbf</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">rbf_regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xs_data</span><span class="p">,</span> <span class="n">ys_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">ys_infer_rbf</span> <span class="o">=</span> <span class="n">rbf_regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">end_rbf</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">times_rbf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">end_rbf</span> <span class="o">-</span> <span class="n">start_rbf</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># rff</span>
</span></span><span class="line"><span class="cl">    <span class="n">start_rff</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">rff</span> <span class="o">=</span> <span class="n">RandomFourierFeature</span><span class="p">(</span><span class="n">n_feature</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">rff_regression</span> <span class="o">=</span> <span class="n">KernelRidgeRegression</span><span class="p">(</span><span class="n">rff</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">rff_regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xs_data</span><span class="p">,</span> <span class="n">ys_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">ys_infer_rff</span> <span class="o">=</span> <span class="n">rff_regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xs_infer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">end_rff</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">times_rff</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">end_rff</span> <span class="o">-</span> <span class="n">start_rff</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>表にまとめると次のようになる。Random Fourier Featuresの方が計算時間が短いことがわかる。
これは一回だけの計測時間なので本当は複数回計測して平均を取った方が良いが、今回は省略する。
あとデータ数をより増やして理論予測される計算量のスケールに一致するかを比較する必要もあるが、今回は省略する。</p>
<table>
<thead>
<tr>
<th style="text-align:right">#data</th>
<th>RBF</th>
<th>RFF</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">$100$</td>
<td>0.0351[s]</td>
<td>0.0234[s]</td>
</tr>
<tr>
<td style="text-align:right">$1000$</td>
<td>0.0361[s]</td>
<td>0.0059[s]</td>
</tr>
<tr>
<td style="text-align:right">$10000$</td>
<td>1.8547[s]</td>
<td>0.0489[s]</td>
</tr>
<tr>
<td style="text-align:right">$20000$</td>
<td>11.0161[s]</td>
<td>0.1733[s]</td>
</tr>
<tr>
<td style="text-align:right">$30000$</td>
<td>34.6534[s]</td>
<td>0.4661[s]</td>
</tr>
</tbody>
</table>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>A. Rahimi, and B. Recht, &ldquo;Random features for large-scale kernel machines.&rdquo; Advances in neural information processing systems 20 (2007). [<a href="https://proceedings.neurips.cc/paper/2007/file/013a006f03dbc5392effeb8f18fda755-Paper.pdf">📁 PDF</a>]&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>この式自体の証明はWoodburyの公式を用いるまでもなく$Z^{\top}(ZZ^{\top}+\lambda I_{n})=(Z^{\top}Z+\lambda I_{m})Z^{\top}$からわかる。&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://yonesuke.github.io/posts/hermite_coeff/">
    <span class="title">« Prev</span>
    <br>
    <span>Hermite多項式の係数</span>
  </a>
  <a class="next" href="https://yonesuke.github.io/posts/auto_install/">
    <span class="title">Next »</span>
    <br>
    <span>AUTOのインストール方法</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Random Fourier Features on twitter"
        href="https://twitter.com/intent/tweet/?text=Random%20Fourier%20Features&amp;url=https%3a%2f%2fyonesuke.github.io%2fposts%2frandom_fourier_feature%2f&amp;hashtags=">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Random Fourier Features on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fyonesuke.github.io%2fposts%2frandom_fourier_feature%2f&amp;title=Random%20Fourier%20Features&amp;summary=Random%20Fourier%20Features&amp;source=https%3a%2f%2fyonesuke.github.io%2fposts%2frandom_fourier_feature%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Random Fourier Features on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fyonesuke.github.io%2fposts%2frandom_fourier_feature%2f&title=Random%20Fourier%20Features">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Random Fourier Features on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fyonesuke.github.io%2fposts%2frandom_fourier_feature%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Random Fourier Features on whatsapp"
        href="https://api.whatsapp.com/send?text=Random%20Fourier%20Features%20-%20https%3a%2f%2fyonesuke.github.io%2fposts%2frandom_fourier_feature%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Random Fourier Features on telegram"
        href="https://telegram.me/share/url?text=Random%20Fourier%20Features&amp;url=https%3a%2f%2fyonesuke.github.io%2fposts%2frandom_fourier_feature%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer><script src="https://utteranc.es/client.js"
        repo="yonesuke/yonesuke.github.io"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://yonesuke.github.io">Ryosuke Yoneda</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
