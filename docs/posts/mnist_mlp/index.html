<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> MNISTをMLPで推論(Julia/Flux実装) | Ryosuke Yoneda&#39;s Homepage</title>
  <meta name="description" content="Hugo is a general-purpose website framework. Technically speaking, Hugo is a static site generator. Unlike systems that dynamically build a page with each visitor request, Hugo builds pages when you create or update your content. Since websites are viewed far more often than they are edited, Hugo is designed to provide an optimal viewing experience for your website’s end users and an ideal writing experience for website authors.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta property="og:title" content="MNISTをMLPで推論(Julia/Flux実装)" />
<meta property="og:description" content="Juliaで機械学習をするための有名なライブラリにFluxがあります。Fluxを使ってMNISTの手書き数字の推論を行ったのでその方法をまとめておきます。 コードは次のようになります。これを参考に書きました。
 パッケージ 基本的にFluxさえあれば良いです。今回はMNISTデータを用いるのでMLDatasetsというパッケージを用いてデータを読み込みます。これらのパッケージは事前にインストールしておく必要があります。JuliaのREPLやnotebook上で次を入力してください。
julia&gt; import Pkg; Pkg.add([&#34;Flux&#34;, &#34;MLDatasets&#34;]) これでパッケージを読み込むことができます。
using Flux using Flux.Data: DataLoader using Flux: onehotbatch, onecold using Flux.Losses: logitcrossentropy using MLDatasets データの読み込み MNISTデータを読み込みます。
x_train, y_train = MLDatasets.MNIST.traindata(Float32) x_test, y_test = MLDatasets.MNIST.testdata(Float32) MNISTの画像はサイズ(28,28,1)になっていますが、MLPには1次元の配列として渡したいのでflattenで各データを1次元に落とします。
x_train = Flux.flatten(x_train) # 784×60000 x_test = Flux.flatten(x_test) # 784×10000 また、各画像の数字(0~9)はone-hotにしておきたいのでそちらはonehotbatchという関数で変換しておきます。
y_train = onehotbatch(y_train, 0:9) # 10×60000 y_test = onehotbatch(y_test, 0:9) # 10×10000 モデルの定義 いよいよモデルの定義です。今回は一番簡単なMLPで実装していきます。
img_size = (28,28,1) input_size = prod(img_size) # 784 nclasses = 10 # 0~9 # Define model model = Chain( Dense(input_size, 32, relu), Dense(32, nclasses) ) Dense(input_size, output_size, f)という関数$F\colon\mathbb{R}^{\mathrm{inputsize}}\to\mathbb{R}^{\mathrm{outputsize}}$は $$ F(x) = f(Wx&#43;b) $$ になります。$f$は活性化関数です。$W,b$は内部で勝手に定義されます。デフォルトでは初期値$W,b$はGlorotの一様分布に従ってランダムに選ばれます。 また、$f$を指定しなければ活性化関数は恒等関数になります。すなわち非線形変換は行われません。 今回は活性化関数にReLU関数を用いました。 Chainは合成関数を作ります。すなわち、Chain(F,G)は$G\circ F$という関数に対応します。 今回定義したモデルは784次元の入力から10次元の出力を返します。出力の10次元の中で一番大きい要素のindexが推定される数字とします。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yonesuke.github.io/posts/mnist_mlp/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-08-23T16:38:35+09:00" />
<meta property="article:modified_time" content="2021-08-23T16:38:35+09:00" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="MNISTをMLPで推論(Julia/Flux実装)"/>
<meta name="twitter:description" content="Juliaで機械学習をするための有名なライブラリにFluxがあります。Fluxを使ってMNISTの手書き数字の推論を行ったのでその方法をまとめておきます。 コードは次のようになります。これを参考に書きました。
 パッケージ 基本的にFluxさえあれば良いです。今回はMNISTデータを用いるのでMLDatasetsというパッケージを用いてデータを読み込みます。これらのパッケージは事前にインストールしておく必要があります。JuliaのREPLやnotebook上で次を入力してください。
julia&gt; import Pkg; Pkg.add([&#34;Flux&#34;, &#34;MLDatasets&#34;]) これでパッケージを読み込むことができます。
using Flux using Flux.Data: DataLoader using Flux: onehotbatch, onecold using Flux.Losses: logitcrossentropy using MLDatasets データの読み込み MNISTデータを読み込みます。
x_train, y_train = MLDatasets.MNIST.traindata(Float32) x_test, y_test = MLDatasets.MNIST.testdata(Float32) MNISTの画像はサイズ(28,28,1)になっていますが、MLPには1次元の配列として渡したいのでflattenで各データを1次元に落とします。
x_train = Flux.flatten(x_train) # 784×60000 x_test = Flux.flatten(x_test) # 784×10000 また、各画像の数字(0~9)はone-hotにしておきたいのでそちらはonehotbatchという関数で変換しておきます。
y_train = onehotbatch(y_train, 0:9) # 10×60000 y_test = onehotbatch(y_test, 0:9) # 10×10000 モデルの定義 いよいよモデルの定義です。今回は一番簡単なMLPで実装していきます。
img_size = (28,28,1) input_size = prod(img_size) # 784 nclasses = 10 # 0~9 # Define model model = Chain( Dense(input_size, 32, relu), Dense(32, nclasses) ) Dense(input_size, output_size, f)という関数$F\colon\mathbb{R}^{\mathrm{inputsize}}\to\mathbb{R}^{\mathrm{outputsize}}$は $$ F(x) = f(Wx&#43;b) $$ になります。$f$は活性化関数です。$W,b$は内部で勝手に定義されます。デフォルトでは初期値$W,b$はGlorotの一様分布に従ってランダムに選ばれます。 また、$f$を指定しなければ活性化関数は恒等関数になります。すなわち非線形変換は行われません。 今回は活性化関数にReLU関数を用いました。 Chainは合成関数を作ります。すなわち、Chain(F,G)は$G\circ F$という関数に対応します。 今回定義したモデルは784次元の入力から10次元の出力を返します。出力の10次元の中で一番大きい要素のindexが推定される数字とします。"/>

  
  
    
  
  
  <link rel="stylesheet" href="https://yonesuke.github.io/css/style-classic.css">
  
  
  
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
<link rel="icon" type="image/png" href="https://yonesuke.github.io/images/favicon.ico" />

  
  
  
  
</head>

<body class="max-width mx-auto px3 ltr">
  <div class="content index py4">

  <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/about">About</a></li>
         
        <li><a href="/research">Research</a></li>
         
        <li><a href="/teaching">Teaching</a></li>
         
        <li><a href="/posts">Posts</a></li>
         
        <li><a href="/cv.pdf">CV</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li>
          <a class="icon" href=" https://yonesuke.github.io/posts/gram_eigen/">
            <i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i>
          </a>
        </li>
        
        
        <li>
          <a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');">
            <i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i>
          </a>
        </li>
        <li>
          <a class="icon" href="#">
            <i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i>
          </a>
        </li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f">
      <i class="fab fa-facebook " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&text=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-twitter " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&title=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-linkedin " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&is_video=false&description=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-pinterest " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29&body=Check out this article: https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f">
      <i class="fas fa-envelope " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&title=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-get-pocket " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&title=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-reddit " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&name=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29&description=Julia%e3%81%a7%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%82%92%e3%81%99%e3%82%8b%e3%81%9f%e3%82%81%e3%81%ae%e6%9c%89%e5%90%8d%e3%81%aa%e3%83%a9%e3%82%a4%e3%83%96%e3%83%a9%e3%83%aa%e3%81%abFlux%e3%81%8c%e3%81%82%e3%82%8a%e3%81%be%e3%81%99%e3%80%82Flux%e3%82%92%e4%bd%bf%e3%81%a3%e3%81%a6MNIST%e3%81%ae%e6%89%8b%e6%9b%b8%e3%81%8d%e6%95%b0%e5%ad%97%e3%81%ae%e6%8e%a8%e8%ab%96%e3%82%92%e8%a1%8c%e3%81%a3%e3%81%9f%e3%81%ae%e3%81%a7%e3%81%9d%e3%81%ae%e6%96%b9%e6%b3%95%e3%82%92%e3%81%be%e3%81%a8%e3%82%81%e3%81%a6%e3%81%8a%e3%81%8d%e3%81%be%e3%81%99%e3%80%82%20%e3%82%b3%e3%83%bc%e3%83%89%e3%81%af%e6%ac%a1%e3%81%ae%e3%82%88%e3%81%86%e3%81%ab%e3%81%aa%e3%82%8a%e3%81%be%e3%81%99%e3%80%82%e3%81%93%e3%82%8c%e3%82%92%e5%8f%82%e8%80%83%e3%81%ab%e6%9b%b8%e3%81%8d%e3%81%be%e3%81%97%e3%81%9f%e3%80%82%0a%20%e3%83%91%e3%83%83%e3%82%b1%e3%83%bc%e3%82%b8%20%e5%9f%ba%e6%9c%ac%e7%9a%84%e3%81%abFlux%e3%81%95%e3%81%88%e3%81%82%e3%82%8c%e3%81%b0%e8%89%af%e3%81%84%e3%81%a7%e3%81%99%e3%80%82%e4%bb%8a%e5%9b%9e%e3%81%afMNIST%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e7%94%a8%e3%81%84%e3%82%8b%e3%81%ae%e3%81%a7MLDatasets%e3%81%a8%e3%81%84%e3%81%86%e3%83%91%e3%83%83%e3%82%b1%e3%83%bc%e3%82%b8%e3%82%92%e7%94%a8%e3%81%84%e3%81%a6%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e8%aa%ad%e3%81%bf%e8%be%bc%e3%81%bf%e3%81%be%e3%81%99%e3%80%82%e3%81%93%e3%82%8c%e3%82%89%e3%81%ae%e3%83%91%e3%83%83%e3%82%b1%e3%83%bc%e3%82%b8%e3%81%af%e4%ba%8b%e5%89%8d%e3%81%ab%e3%82%a4%e3%83%b3%e3%82%b9%e3%83%88%e3%83%bc%e3%83%ab%e3%81%97%e3%81%a6%e3%81%8a%e3%81%8f%e5%bf%85%e8%a6%81%e3%81%8c%e3%81%82%e3%82%8a%e3%81%be%e3%81%99%e3%80%82Julia%e3%81%aeREPL%e3%82%84notebook%e4%b8%8a%e3%81%a7%e6%ac%a1%e3%82%92%e5%85%a5%e5%8a%9b%e3%81%97%e3%81%a6%e3%81%8f%e3%81%a0%e3%81%95%e3%81%84%e3%80%82%0ajulia%26gt%3b%20import%20Pkg%3b%20Pkg.add%28%5b%26%2334%3bFlux%26%2334%3b%2c%20%26%2334%3bMLDatasets%26%2334%3b%5d%29%20%e3%81%93%e3%82%8c%e3%81%a7%e3%83%91%e3%83%83%e3%82%b1%e3%83%bc%e3%82%b8%e3%82%92%e8%aa%ad%e3%81%bf%e8%be%bc%e3%82%80%e3%81%93%e3%81%a8%e3%81%8c%e3%81%a7%e3%81%8d%e3%81%be%e3%81%99%e3%80%82%0ausing%20Flux%20using%20Flux.Data%3a%20DataLoader%20using%20Flux%3a%20onehotbatch%2c%20onecold%20using%20Flux.Losses%3a%20logitcrossentropy%20using%20MLDatasets%20%e3%83%87%e3%83%bc%e3%82%bf%e3%81%ae%e8%aa%ad%e3%81%bf%e8%be%bc%e3%81%bf%20MNIST%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e8%aa%ad%e3%81%bf%e8%be%bc%e3%81%bf%e3%81%be%e3%81%99%e3%80%82%0ax_train%2c%20y_train%20%3d%20MLDatasets.MNIST.traindata%28Float32%29%20x_test%2c%20y_test%20%3d%20MLDatasets.MNIST.testdata%28Float32%29%20MNIST%e3%81%ae%e7%94%bb%e5%83%8f%e3%81%af%e3%82%b5%e3%82%a4%e3%82%ba%2828%2c28%2c1%29%e3%81%ab%e3%81%aa%e3%81%a3%e3%81%a6%e3%81%84%e3%81%be%e3%81%99%e3%81%8c%e3%80%81MLP%e3%81%ab%e3%81%af1%e6%ac%a1%e5%85%83%e3%81%ae%e9%85%8d%e5%88%97%e3%81%a8%e3%81%97%e3%81%a6%e6%b8%a1%e3%81%97%e3%81%9f%e3%81%84%e3%81%ae%e3%81%a7flatten%e3%81%a7%e5%90%84%e3%83%87%e3%83%bc%e3%82%bf%e3%82%921%e6%ac%a1%e5%85%83%e3%81%ab%e8%90%bd%e3%81%a8%e3%81%97%e3%81%be%e3%81%99%e3%80%82%0ax_train%20%3d%20Flux.flatten%28x_train%29%20%23%20784%c3%9760000%20x_test%20%3d%20Flux.flatten%28x_test%29%20%23%20784%c3%9710000%20%e3%81%be%e3%81%9f%e3%80%81%e5%90%84%e7%94%bb%e5%83%8f%e3%81%ae%e6%95%b0%e5%ad%97%280~9%29%e3%81%afone-hot%e3%81%ab%e3%81%97%e3%81%a6%e3%81%8a%e3%81%8d%e3%81%9f%e3%81%84%e3%81%ae%e3%81%a7%e3%81%9d%e3%81%a1%e3%82%89%e3%81%afonehotbatch%e3%81%a8%e3%81%84%e3%81%86%e9%96%a2%e6%95%b0%e3%81%a7%e5%a4%89%e6%8f%9b%e3%81%97%e3%81%a6%e3%81%8a%e3%81%8d%e3%81%be%e3%81%99%e3%80%82%0ay_train%20%3d%20onehotbatch%28y_train%2c%200%3a9%29%20%23%2010%c3%9760000%20y_test%20%3d%20onehotbatch%28y_test%2c%200%3a9%29%20%23%2010%c3%9710000%20%e3%83%a2%e3%83%87%e3%83%ab%e3%81%ae%e5%ae%9a%e7%be%a9%20%e3%81%84%e3%82%88%e3%81%84%e3%82%88%e3%83%a2%e3%83%87%e3%83%ab%e3%81%ae%e5%ae%9a%e7%be%a9%e3%81%a7%e3%81%99%e3%80%82%e4%bb%8a%e5%9b%9e%e3%81%af%e4%b8%80%e7%95%aa%e7%b0%a1%e5%8d%98%e3%81%aaMLP%e3%81%a7%e5%ae%9f%e8%a3%85%e3%81%97%e3%81%a6%e3%81%84%e3%81%8d%e3%81%be%e3%81%99%e3%80%82%0aimg_size%20%3d%20%2828%2c28%2c1%29%20input_size%20%3d%20prod%28img_size%29%20%23%20784%20nclasses%20%3d%2010%20%23%200~9%20%23%20Define%20model%20model%20%3d%20Chain%28%20Dense%28input_size%2c%2032%2c%20relu%29%2c%20Dense%2832%2c%20nclasses%29%20%29%20Dense%28input_size%2c%20output_size%2c%20f%29%e3%81%a8%e3%81%84%e3%81%86%e9%96%a2%e6%95%b0%24F%5ccolon%5cmathbb%7bR%7d%5e%7b%5cmathrm%7binputsize%7d%7d%5cto%5cmathbb%7bR%7d%5e%7b%5cmathrm%7boutputsize%7d%7d%24%e3%81%af%20%24%24%20F%28x%29%20%3d%20f%28Wx%2bb%29%20%24%24%20%e3%81%ab%e3%81%aa%e3%82%8a%e3%81%be%e3%81%99%e3%80%82%24f%24%e3%81%af%e6%b4%bb%e6%80%a7%e5%8c%96%e9%96%a2%e6%95%b0%e3%81%a7%e3%81%99%e3%80%82%24W%2cb%24%e3%81%af%e5%86%85%e9%83%a8%e3%81%a7%e5%8b%9d%e6%89%8b%e3%81%ab%e5%ae%9a%e7%be%a9%e3%81%95%e3%82%8c%e3%81%be%e3%81%99%e3%80%82%e3%83%87%e3%83%95%e3%82%a9%e3%83%ab%e3%83%88%e3%81%a7%e3%81%af%e5%88%9d%e6%9c%9f%e5%80%a4%24W%2cb%24%e3%81%afGlorot%e3%81%ae%e4%b8%80%e6%a7%98%e5%88%86%e5%b8%83%e3%81%ab%e5%be%93%e3%81%a3%e3%81%a6%e3%83%a9%e3%83%b3%e3%83%80%e3%83%a0%e3%81%ab%e9%81%b8%e3%81%b0%e3%82%8c%e3%81%be%e3%81%99%e3%80%82%20%e3%81%be%e3%81%9f%e3%80%81%24f%24%e3%82%92%e6%8c%87%e5%ae%9a%e3%81%97%e3%81%aa%e3%81%91%e3%82%8c%e3%81%b0%e6%b4%bb%e6%80%a7%e5%8c%96%e9%96%a2%e6%95%b0%e3%81%af%e6%81%92%e7%ad%89%e9%96%a2%e6%95%b0%e3%81%ab%e3%81%aa%e3%82%8a%e3%81%be%e3%81%99%e3%80%82%e3%81%99%e3%81%aa%e3%82%8f%e3%81%a1%e9%9d%9e%e7%b7%9a%e5%bd%a2%e5%a4%89%e6%8f%9b%e3%81%af%e8%a1%8c%e3%82%8f%e3%82%8c%e3%81%be%e3%81%9b%e3%82%93%e3%80%82%20%e4%bb%8a%e5%9b%9e%e3%81%af%e6%b4%bb%e6%80%a7%e5%8c%96%e9%96%a2%e6%95%b0%e3%81%abReLU%e9%96%a2%e6%95%b0%e3%82%92%e7%94%a8%e3%81%84%e3%81%be%e3%81%97%e3%81%9f%e3%80%82%20Chain%e3%81%af%e5%90%88%e6%88%90%e9%96%a2%e6%95%b0%e3%82%92%e4%bd%9c%e3%82%8a%e3%81%be%e3%81%99%e3%80%82%e3%81%99%e3%81%aa%e3%82%8f%e3%81%a1%e3%80%81Chain%28F%2cG%29%e3%81%af%24G%5ccirc%20F%24%e3%81%a8%e3%81%84%e3%81%86%e9%96%a2%e6%95%b0%e3%81%ab%e5%af%be%e5%bf%9c%e3%81%97%e3%81%be%e3%81%99%e3%80%82%20%e4%bb%8a%e5%9b%9e%e5%ae%9a%e7%be%a9%e3%81%97%e3%81%9f%e3%83%a2%e3%83%87%e3%83%ab%e3%81%af784%e6%ac%a1%e5%85%83%e3%81%ae%e5%85%a5%e5%8a%9b%e3%81%8b%e3%82%8910%e6%ac%a1%e5%85%83%e3%81%ae%e5%87%ba%e5%8a%9b%e3%82%92%e8%bf%94%e3%81%97%e3%81%be%e3%81%99%e3%80%82%e5%87%ba%e5%8a%9b%e3%81%ae10%e6%ac%a1%e5%85%83%e3%81%ae%e4%b8%ad%e3%81%a7%e4%b8%80%e7%95%aa%e5%a4%a7%e3%81%8d%e3%81%84%e8%a6%81%e7%b4%a0%e3%81%aeindex%e3%81%8c%e6%8e%a8%e5%ae%9a%e3%81%95%e3%82%8c%e3%82%8b%e6%95%b0%e5%ad%97%e3%81%a8%e3%81%97%e3%81%be%e3%81%99%e3%80%82">
      <i class="fab fa-tumblr " aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&t=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-hacker-news " aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>
    <div id="toc">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#パッケージ">パッケージ</a></li>
    <li><a href="#データの読み込み">データの読み込み</a></li>
    <li><a href="#モデルの定義">モデルの定義</a></li>
    <li><a href="#学習の準備">学習の準備</a></li>
    <li><a href="#損失関数">損失関数</a></li>
    <li><a href="#学習">学習</a></li>
  </ul>
</nav>
    </div>
  </span>
</div>


  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 class="posttitle" itemprop="name headline">
        MNISTをMLPで推論(Julia/Flux実装)
      </h1>
      <div class="meta">
        
        <div class="postdate">
          
          <time datetime="2021-08-23 16:38:35 &#43;0900 JST" itemprop="datePublished">2021-08-23</time>
          
        </div>
        
        
      </div>
    </header>


    <div class="content" itemprop="articleBody">
      <p>Juliaで機械学習をするための有名なライブラリに<a href="https://github.com/FluxML/Flux.jl">Flux</a>があります。Fluxを使ってMNISTの手書き数字の推論を行ったのでその方法をまとめておきます。
コードは次のようになります。<a href="https://github.com/FluxML/model-zoo/blob/master/vision/mlp_mnist/mlp_mnist.jl">これ</a>を参考に書きました。</p>
<script type="application/javascript" src="https://gist.github.com/yonesuke/afc39543fb1de5ff484fa812e3ca5a1d.js"></script>

<h2 id="パッケージ">パッケージ</h2>
<p>基本的に<code>Flux</code>さえあれば良いです。今回はMNISTデータを用いるので<code>MLDatasets</code>というパッケージを用いてデータを読み込みます。これらのパッケージは事前にインストールしておく必要があります。JuliaのREPLやnotebook上で次を入力してください。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">julia<span style="color:#f92672">&gt;</span> <span style="color:#66d9ef">import</span> Pkg; Pkg<span style="color:#f92672">.</span>add([<span style="color:#e6db74">&#34;Flux&#34;</span>, <span style="color:#e6db74">&#34;MLDatasets&#34;</span>])
</code></pre></div><p>これでパッケージを読み込むことができます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">using</span> Flux
<span style="color:#66d9ef">using</span> Flux<span style="color:#f92672">.</span>Data<span style="color:#f92672">:</span> DataLoader
<span style="color:#66d9ef">using</span> Flux<span style="color:#f92672">:</span> onehotbatch, onecold
<span style="color:#66d9ef">using</span> Flux<span style="color:#f92672">.</span>Losses<span style="color:#f92672">:</span> logitcrossentropy
<span style="color:#66d9ef">using</span> MLDatasets
</code></pre></div><h2 id="データの読み込み">データの読み込み</h2>
<p>MNISTデータを読み込みます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">x_train, y_train <span style="color:#f92672">=</span> MLDatasets<span style="color:#f92672">.</span>MNIST<span style="color:#f92672">.</span>traindata(<span style="color:#66d9ef">Float32</span>)
x_test, y_test <span style="color:#f92672">=</span> MLDatasets<span style="color:#f92672">.</span>MNIST<span style="color:#f92672">.</span>testdata(<span style="color:#66d9ef">Float32</span>)
</code></pre></div><p>MNISTの画像はサイズ(28,28,1)になっていますが、MLPには1次元の配列として渡したいので<code>flatten</code>で各データを1次元に落とします。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">x_train <span style="color:#f92672">=</span> Flux<span style="color:#f92672">.</span>flatten(x_train) <span style="color:#75715e"># 784×60000</span>
x_test <span style="color:#f92672">=</span> Flux<span style="color:#f92672">.</span>flatten(x_test) <span style="color:#75715e"># 784×10000</span>
</code></pre></div><p>また、各画像の数字(0~9)はone-hotにしておきたいのでそちらは<code>onehotbatch</code>という関数で変換しておきます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">y_train <span style="color:#f92672">=</span> onehotbatch(y_train, <span style="color:#ae81ff">0</span><span style="color:#f92672">:</span><span style="color:#ae81ff">9</span>) <span style="color:#75715e"># 10×60000</span>
y_test <span style="color:#f92672">=</span> onehotbatch(y_test, <span style="color:#ae81ff">0</span><span style="color:#f92672">:</span><span style="color:#ae81ff">9</span>) <span style="color:#75715e"># 10×10000</span>
</code></pre></div><h2 id="モデルの定義">モデルの定義</h2>
<p>いよいよモデルの定義です。今回は一番簡単なMLPで実装していきます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">img_size <span style="color:#f92672">=</span> (<span style="color:#ae81ff">28</span>,<span style="color:#ae81ff">28</span>,<span style="color:#ae81ff">1</span>)
input_size <span style="color:#f92672">=</span> prod(img_size) <span style="color:#75715e"># 784</span>
nclasses <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span> <span style="color:#75715e"># 0~9</span>
<span style="color:#75715e"># Define model</span>
model <span style="color:#f92672">=</span> Chain(
    Dense(input_size, <span style="color:#ae81ff">32</span>, relu),
    Dense(<span style="color:#ae81ff">32</span>, nclasses)
)
</code></pre></div><p><code>Dense(input_size, output_size, f)</code>という関数$F\colon\mathbb{R}^{\mathrm{inputsize}}\to\mathbb{R}^{\mathrm{outputsize}}$は
$$
F(x) = f(Wx+b)
$$
になります。$f$は活性化関数です。$W,b$は内部で勝手に定義されます。デフォルトでは初期値$W,b$はGlorotの一様分布に従ってランダムに選ばれます。
また、$f$を指定しなければ活性化関数は恒等関数になります。すなわち非線形変換は行われません。
今回は活性化関数にReLU関数を用いました。
<code>Chain</code>は合成関数を作ります。すなわち、<code>Chain(F,G)</code>は$G\circ F$という関数に対応します。
今回定義したモデルは784次元の入力から10次元の出力を返します。出力の10次元の中で一番大きい要素のindexが推定される数字とします。</p>
<p>定義したモデルから学習すべきパラメータを取り出しておきます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">parameters <span style="color:#f92672">=</span> Flux<span style="color:#f92672">.</span>params(model)
</code></pre></div><h2 id="学習の準備">学習の準備</h2>
<p>データが多いのでミニバッチ学習を行いましょう。バッチサイズとエポック数を定義します。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>
epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>
</code></pre></div><p>これをもとにtrainデータとtestデータをバッチに分けていきます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">train_loader <span style="color:#f92672">=</span> DataLoader((x_train, y_train), batchsize<span style="color:#f92672">=</span>batch_size, shuffle<span style="color:#f92672">=</span>true)
test_loader <span style="color:#f92672">=</span> DataLoader((x_test, y_test), batchsize<span style="color:#f92672">=</span>batch_size, shuffle<span style="color:#f92672">=</span>true)
</code></pre></div><p>また、学習則にはAdamを用いてみましょう。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">opt <span style="color:#f92672">=</span> ADAM()
</code></pre></div><h2 id="損失関数">損失関数</h2>
<p>損失関数を定義します。入力<code>x</code>に対して出力<code>ŷ=model(x)</code>は10次元のベクトルになりますが、これは特に正規化されていません。本来は出力の段階でsoftmax関数で正規化すべきかもしれませんが、推定の意味においては最大値を取りさえすれば良いので特に問題はありません。
また、softmaxを通した10次元の離散分布<code>softmax(ŷ)</code>とone-hotの分布<code>y</code>の間の交差エントロピー<code>crossentropy(softmax(ŷ), y)</code>を計算すると数値的な誤差が生まれやすいことが知られています。
数学的にこれと等価な<code>logitcrossentropy(ŷ, y)=crossentropy(softmax(ŷ), y)</code>を用いたほうが数値的にも安定します。
よって損失関数は次のように定義します。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">function</span> loss(x, y)
    ŷ <span style="color:#f92672">=</span> model(x)
    <span style="color:#66d9ef">return</span> logitcrossentropy(ŷ, y, agg<span style="color:#f92672">=</span>sum)
<span style="color:#66d9ef">end</span>
</code></pre></div><p>また、epochごとの損失関数の値と精度を計測する関数も定義しておきます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">function</span> loss_accuracy(loader)
    acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
    ls <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
    num <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">for</span> (x, y) <span style="color:#66d9ef">in</span> loader
        ŷ <span style="color:#f92672">=</span> model(x)
        ls <span style="color:#f92672">+=</span> logitcrossentropy(ŷ, y, agg<span style="color:#f92672">=</span>sum)
        acc <span style="color:#f92672">+=</span> sum(onecold(ŷ) <span style="color:#f92672">.==</span> onecold(y))
        num <span style="color:#f92672">+=</span>  size(x, <span style="color:#ae81ff">2</span>)
    <span style="color:#66d9ef">end</span>
    <span style="color:#66d9ef">return</span> ls<span style="color:#f92672">/</span>num, acc<span style="color:#f92672">/</span>num
<span style="color:#66d9ef">end</span>
</code></pre></div><h2 id="学習">学習</h2>
<p>いよいよ学習させます。各エポックごとにtrainデータとtestデータのlossと精度を出力する関数を定義しておきます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">function</span> callback(epoch)
    println(<span style="color:#e6db74">&#34;Epoch=</span><span style="color:#e6db74">$epoch</span><span style="color:#e6db74">&#34;</span>)
    train_loss, train_accuracy <span style="color:#f92672">=</span> loss_accuracy(train_loader)
    test_loss, test_accuracy <span style="color:#f92672">=</span> loss_accuracy(test_loader)
    println(<span style="color:#e6db74">&#34;    train_loss = </span><span style="color:#e6db74">$train_loss</span><span style="color:#e6db74">, train_accuracy = </span><span style="color:#e6db74">$train_accuracy</span><span style="color:#e6db74">&#34;</span>)
    println(<span style="color:#e6db74">&#34;    test_loss = </span><span style="color:#e6db74">$test_loss</span><span style="color:#e6db74">, test_accuracy = </span><span style="color:#e6db74">$test_accuracy</span><span style="color:#e6db74">&#34;</span>)
<span style="color:#66d9ef">end</span>
</code></pre></div><p>Flux内の<code>Flux.train!</code>関数でミニバッチ学習をしてもらいます。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">for</span> epoch <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>epochs
    Flux<span style="color:#f92672">.</span>train!(loss, parameters, train_loader, opt)
    callback(epoch)
<span style="color:#66d9ef">end</span>
</code></pre></div><p>10エポックの学習で96％近くの学習精度を達成できます。</p>
<pre tabindex="0"><code>...
Epoch=10
    train_loss = 0.12148669401804606, train_accuracy = 0.9660333333333333
    test_loss = 0.14259111329317092, test_accuracy = 0.9594
</code></pre><p>また、手元の環境(M1 mac mini)で10エポック回すのに6.03秒かかりました。GPUとかは使わなくてもここまでの速度と精度が出るのは素晴らしいですね。</p>

    </div>
  </article>

  
  





  <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about">About</a></li>
         
          <li><a href="/research">Research</a></li>
         
          <li><a href="/teaching">Teaching</a></li>
         
          <li><a href="/posts">Posts</a></li>
         
          <li><a href="/cv.pdf">CV</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#パッケージ">パッケージ</a></li>
    <li><a href="#データの読み込み">データの読み込み</a></li>
    <li><a href="#モデルの定義">モデルの定義</a></li>
    <li><a href="#学習の準備">学習の準備</a></li>
    <li><a href="#損失関数">損失関数</a></li>
    <li><a href="#学習">学習</a></li>
  </ul>
</nav>
    </div>

    <div id="share-footer" style="display: none">
      
      <ul>
  
  
    
  
  
  <li>
    <a class="icon" href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f">
      <i class="fab fa-facebook fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://twitter.com/share?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&text=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-twitter fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&title=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&is_video=false&description=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-pinterest fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="mailto:?subject=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29&body=Check out this article: https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f">
      <i class="fas fa-envelope fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://getpocket.com/save?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&title=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://reddit.com/submit?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&title=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-reddit fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="http://www.tumblr.com/share/link?url=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&name=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29&description=Julia%e3%81%a7%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%82%92%e3%81%99%e3%82%8b%e3%81%9f%e3%82%81%e3%81%ae%e6%9c%89%e5%90%8d%e3%81%aa%e3%83%a9%e3%82%a4%e3%83%96%e3%83%a9%e3%83%aa%e3%81%abFlux%e3%81%8c%e3%81%82%e3%82%8a%e3%81%be%e3%81%99%e3%80%82Flux%e3%82%92%e4%bd%bf%e3%81%a3%e3%81%a6MNIST%e3%81%ae%e6%89%8b%e6%9b%b8%e3%81%8d%e6%95%b0%e5%ad%97%e3%81%ae%e6%8e%a8%e8%ab%96%e3%82%92%e8%a1%8c%e3%81%a3%e3%81%9f%e3%81%ae%e3%81%a7%e3%81%9d%e3%81%ae%e6%96%b9%e6%b3%95%e3%82%92%e3%81%be%e3%81%a8%e3%82%81%e3%81%a6%e3%81%8a%e3%81%8d%e3%81%be%e3%81%99%e3%80%82%20%e3%82%b3%e3%83%bc%e3%83%89%e3%81%af%e6%ac%a1%e3%81%ae%e3%82%88%e3%81%86%e3%81%ab%e3%81%aa%e3%82%8a%e3%81%be%e3%81%99%e3%80%82%e3%81%93%e3%82%8c%e3%82%92%e5%8f%82%e8%80%83%e3%81%ab%e6%9b%b8%e3%81%8d%e3%81%be%e3%81%97%e3%81%9f%e3%80%82%0a%20%e3%83%91%e3%83%83%e3%82%b1%e3%83%bc%e3%82%b8%20%e5%9f%ba%e6%9c%ac%e7%9a%84%e3%81%abFlux%e3%81%95%e3%81%88%e3%81%82%e3%82%8c%e3%81%b0%e8%89%af%e3%81%84%e3%81%a7%e3%81%99%e3%80%82%e4%bb%8a%e5%9b%9e%e3%81%afMNIST%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e7%94%a8%e3%81%84%e3%82%8b%e3%81%ae%e3%81%a7MLDatasets%e3%81%a8%e3%81%84%e3%81%86%e3%83%91%e3%83%83%e3%82%b1%e3%83%bc%e3%82%b8%e3%82%92%e7%94%a8%e3%81%84%e3%81%a6%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e8%aa%ad%e3%81%bf%e8%be%bc%e3%81%bf%e3%81%be%e3%81%99%e3%80%82%e3%81%93%e3%82%8c%e3%82%89%e3%81%ae%e3%83%91%e3%83%83%e3%82%b1%e3%83%bc%e3%82%b8%e3%81%af%e4%ba%8b%e5%89%8d%e3%81%ab%e3%82%a4%e3%83%b3%e3%82%b9%e3%83%88%e3%83%bc%e3%83%ab%e3%81%97%e3%81%a6%e3%81%8a%e3%81%8f%e5%bf%85%e8%a6%81%e3%81%8c%e3%81%82%e3%82%8a%e3%81%be%e3%81%99%e3%80%82Julia%e3%81%aeREPL%e3%82%84notebook%e4%b8%8a%e3%81%a7%e6%ac%a1%e3%82%92%e5%85%a5%e5%8a%9b%e3%81%97%e3%81%a6%e3%81%8f%e3%81%a0%e3%81%95%e3%81%84%e3%80%82%0ajulia%26gt%3b%20import%20Pkg%3b%20Pkg.add%28%5b%26%2334%3bFlux%26%2334%3b%2c%20%26%2334%3bMLDatasets%26%2334%3b%5d%29%20%e3%81%93%e3%82%8c%e3%81%a7%e3%83%91%e3%83%83%e3%82%b1%e3%83%bc%e3%82%b8%e3%82%92%e8%aa%ad%e3%81%bf%e8%be%bc%e3%82%80%e3%81%93%e3%81%a8%e3%81%8c%e3%81%a7%e3%81%8d%e3%81%be%e3%81%99%e3%80%82%0ausing%20Flux%20using%20Flux.Data%3a%20DataLoader%20using%20Flux%3a%20onehotbatch%2c%20onecold%20using%20Flux.Losses%3a%20logitcrossentropy%20using%20MLDatasets%20%e3%83%87%e3%83%bc%e3%82%bf%e3%81%ae%e8%aa%ad%e3%81%bf%e8%be%bc%e3%81%bf%20MNIST%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e8%aa%ad%e3%81%bf%e8%be%bc%e3%81%bf%e3%81%be%e3%81%99%e3%80%82%0ax_train%2c%20y_train%20%3d%20MLDatasets.MNIST.traindata%28Float32%29%20x_test%2c%20y_test%20%3d%20MLDatasets.MNIST.testdata%28Float32%29%20MNIST%e3%81%ae%e7%94%bb%e5%83%8f%e3%81%af%e3%82%b5%e3%82%a4%e3%82%ba%2828%2c28%2c1%29%e3%81%ab%e3%81%aa%e3%81%a3%e3%81%a6%e3%81%84%e3%81%be%e3%81%99%e3%81%8c%e3%80%81MLP%e3%81%ab%e3%81%af1%e6%ac%a1%e5%85%83%e3%81%ae%e9%85%8d%e5%88%97%e3%81%a8%e3%81%97%e3%81%a6%e6%b8%a1%e3%81%97%e3%81%9f%e3%81%84%e3%81%ae%e3%81%a7flatten%e3%81%a7%e5%90%84%e3%83%87%e3%83%bc%e3%82%bf%e3%82%921%e6%ac%a1%e5%85%83%e3%81%ab%e8%90%bd%e3%81%a8%e3%81%97%e3%81%be%e3%81%99%e3%80%82%0ax_train%20%3d%20Flux.flatten%28x_train%29%20%23%20784%c3%9760000%20x_test%20%3d%20Flux.flatten%28x_test%29%20%23%20784%c3%9710000%20%e3%81%be%e3%81%9f%e3%80%81%e5%90%84%e7%94%bb%e5%83%8f%e3%81%ae%e6%95%b0%e5%ad%97%280~9%29%e3%81%afone-hot%e3%81%ab%e3%81%97%e3%81%a6%e3%81%8a%e3%81%8d%e3%81%9f%e3%81%84%e3%81%ae%e3%81%a7%e3%81%9d%e3%81%a1%e3%82%89%e3%81%afonehotbatch%e3%81%a8%e3%81%84%e3%81%86%e9%96%a2%e6%95%b0%e3%81%a7%e5%a4%89%e6%8f%9b%e3%81%97%e3%81%a6%e3%81%8a%e3%81%8d%e3%81%be%e3%81%99%e3%80%82%0ay_train%20%3d%20onehotbatch%28y_train%2c%200%3a9%29%20%23%2010%c3%9760000%20y_test%20%3d%20onehotbatch%28y_test%2c%200%3a9%29%20%23%2010%c3%9710000%20%e3%83%a2%e3%83%87%e3%83%ab%e3%81%ae%e5%ae%9a%e7%be%a9%20%e3%81%84%e3%82%88%e3%81%84%e3%82%88%e3%83%a2%e3%83%87%e3%83%ab%e3%81%ae%e5%ae%9a%e7%be%a9%e3%81%a7%e3%81%99%e3%80%82%e4%bb%8a%e5%9b%9e%e3%81%af%e4%b8%80%e7%95%aa%e7%b0%a1%e5%8d%98%e3%81%aaMLP%e3%81%a7%e5%ae%9f%e8%a3%85%e3%81%97%e3%81%a6%e3%81%84%e3%81%8d%e3%81%be%e3%81%99%e3%80%82%0aimg_size%20%3d%20%2828%2c28%2c1%29%20input_size%20%3d%20prod%28img_size%29%20%23%20784%20nclasses%20%3d%2010%20%23%200~9%20%23%20Define%20model%20model%20%3d%20Chain%28%20Dense%28input_size%2c%2032%2c%20relu%29%2c%20Dense%2832%2c%20nclasses%29%20%29%20Dense%28input_size%2c%20output_size%2c%20f%29%e3%81%a8%e3%81%84%e3%81%86%e9%96%a2%e6%95%b0%24F%5ccolon%5cmathbb%7bR%7d%5e%7b%5cmathrm%7binputsize%7d%7d%5cto%5cmathbb%7bR%7d%5e%7b%5cmathrm%7boutputsize%7d%7d%24%e3%81%af%20%24%24%20F%28x%29%20%3d%20f%28Wx%2bb%29%20%24%24%20%e3%81%ab%e3%81%aa%e3%82%8a%e3%81%be%e3%81%99%e3%80%82%24f%24%e3%81%af%e6%b4%bb%e6%80%a7%e5%8c%96%e9%96%a2%e6%95%b0%e3%81%a7%e3%81%99%e3%80%82%24W%2cb%24%e3%81%af%e5%86%85%e9%83%a8%e3%81%a7%e5%8b%9d%e6%89%8b%e3%81%ab%e5%ae%9a%e7%be%a9%e3%81%95%e3%82%8c%e3%81%be%e3%81%99%e3%80%82%e3%83%87%e3%83%95%e3%82%a9%e3%83%ab%e3%83%88%e3%81%a7%e3%81%af%e5%88%9d%e6%9c%9f%e5%80%a4%24W%2cb%24%e3%81%afGlorot%e3%81%ae%e4%b8%80%e6%a7%98%e5%88%86%e5%b8%83%e3%81%ab%e5%be%93%e3%81%a3%e3%81%a6%e3%83%a9%e3%83%b3%e3%83%80%e3%83%a0%e3%81%ab%e9%81%b8%e3%81%b0%e3%82%8c%e3%81%be%e3%81%99%e3%80%82%20%e3%81%be%e3%81%9f%e3%80%81%24f%24%e3%82%92%e6%8c%87%e5%ae%9a%e3%81%97%e3%81%aa%e3%81%91%e3%82%8c%e3%81%b0%e6%b4%bb%e6%80%a7%e5%8c%96%e9%96%a2%e6%95%b0%e3%81%af%e6%81%92%e7%ad%89%e9%96%a2%e6%95%b0%e3%81%ab%e3%81%aa%e3%82%8a%e3%81%be%e3%81%99%e3%80%82%e3%81%99%e3%81%aa%e3%82%8f%e3%81%a1%e9%9d%9e%e7%b7%9a%e5%bd%a2%e5%a4%89%e6%8f%9b%e3%81%af%e8%a1%8c%e3%82%8f%e3%82%8c%e3%81%be%e3%81%9b%e3%82%93%e3%80%82%20%e4%bb%8a%e5%9b%9e%e3%81%af%e6%b4%bb%e6%80%a7%e5%8c%96%e9%96%a2%e6%95%b0%e3%81%abReLU%e9%96%a2%e6%95%b0%e3%82%92%e7%94%a8%e3%81%84%e3%81%be%e3%81%97%e3%81%9f%e3%80%82%20Chain%e3%81%af%e5%90%88%e6%88%90%e9%96%a2%e6%95%b0%e3%82%92%e4%bd%9c%e3%82%8a%e3%81%be%e3%81%99%e3%80%82%e3%81%99%e3%81%aa%e3%82%8f%e3%81%a1%e3%80%81Chain%28F%2cG%29%e3%81%af%24G%5ccirc%20F%24%e3%81%a8%e3%81%84%e3%81%86%e9%96%a2%e6%95%b0%e3%81%ab%e5%af%be%e5%bf%9c%e3%81%97%e3%81%be%e3%81%99%e3%80%82%20%e4%bb%8a%e5%9b%9e%e5%ae%9a%e7%be%a9%e3%81%97%e3%81%9f%e3%83%a2%e3%83%87%e3%83%ab%e3%81%af784%e6%ac%a1%e5%85%83%e3%81%ae%e5%85%a5%e5%8a%9b%e3%81%8b%e3%82%8910%e6%ac%a1%e5%85%83%e3%81%ae%e5%87%ba%e5%8a%9b%e3%82%92%e8%bf%94%e3%81%97%e3%81%be%e3%81%99%e3%80%82%e5%87%ba%e5%8a%9b%e3%81%ae10%e6%ac%a1%e5%85%83%e3%81%ae%e4%b8%ad%e3%81%a7%e4%b8%80%e7%95%aa%e5%a4%a7%e3%81%8d%e3%81%84%e8%a6%81%e7%b4%a0%e3%81%aeindex%e3%81%8c%e6%8e%a8%e5%ae%9a%e3%81%95%e3%82%8c%e3%82%8b%e6%95%b0%e5%ad%97%e3%81%a8%e3%81%97%e3%81%be%e3%81%99%e3%80%82">
      <i class="fab fa-tumblr fa-lg" aria-hidden="true"></i>
    </a>
  </li>
  <li>
    <a class="icon" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fyonesuke.github.io%2fposts%2fmnist_mlp%2f&t=MNIST%e3%82%92MLP%e3%81%a7%e6%8e%a8%e8%ab%96%28Julia%2fFlux%e5%ae%9f%e8%a3%85%29">
      <i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i>
    </a>
  </li>
</ul>

    </div>

    <div id="actions-footer">
      
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;">
          <i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;">
          <i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;">
          <i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');">
          <i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>


  <footer id="footer">
  <div class="footer-left">
    Copyright  &copy; 2021  Ryosuke Yoneda 
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
        <li><a href="/">Home</a></li>
         
        <li><a href="/about">About</a></li>
         
        <li><a href="/research">Research</a></li>
         
        <li><a href="/teaching">Teaching</a></li>
         
        <li><a href="/posts">Posts</a></li>
         
        <li><a href="/cv.pdf">CV</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.css" integrity="sha384-dbVIfZGuN1Yq7/1Ocstc1lUEm+AT+/rCkibIcC/OmWo5f0EA48Vf8CytHzGrSwbQ" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.min.js" integrity="sha384-2BKqo+exmr9su6dir+qCw08N2ZKRucY4PrGQPPWU1A7FtlCGjmEGFqXCv5nyM5Ij" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "$", right: "$", display: false}]
    });
  });
</script>

  </div>
</body>

<link rel="stylesheet" href=/lib/font-awesome/css/all.min.css>
<script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>



</html>
